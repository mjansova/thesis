\appendix
\renewcommand\chaptername{Appendix}                      % hereafter, chapters are called "Appendix"
\renewcommand\thechapter{\Alph{chapter}}                % chapter number in alph letters
\renewcommand\thesection{\Alph{chapter}.\Roman{section}} % make sections "A.I"
\setcounter{chapter}{0}   
%\renewcommand\chaptername{Appendix}
%\appendixwithnum{Résumé en français de mes travaux de thèse -- résultats principaux et discussion}
\appendixwithnum{Résumé en français de mes travaux de thèse: résultats principaux et discussion}

Pendant ma thèse, je j'ai travaillé dans une équipe qui fait partie de la collaboration CMS. Le détecteur ``Compact Muon Solenoid''~(CMS) montré  à la Fig.~\ref{fig:figures/cmsdetector2} est un détecteur de physique des particules situé au CERN en Suisse, auprès du Large Hadron Collider~(LHC), un accélérateur circulaire de particules de 27 km de long qui fournit des collisions de protons à une énergie dans le centre de masse de 13 TeV depuis 2015 (Run II).

    \insertFigure{figures/cmsdetector2} % Filename = label
                 {0.99}       % Width, in fraction of the whole page width
                 { Schéma du détecteur de CMS~\cite{website:CMSdet}. }


Le programme de physique de CMS couvre principalement des mesures de précision du Modèle Standard~(MS) avec un énorme effort dédié aux études du boson de Higgs, ainsi que la recherche de phénomènes au-delà du MS aussi appelée recherche de ``nouvelle physique''.

\section{Introduction}


Cette thèse a commencé en octobre 2015, la même année que le début de la période de prise de données appelée Run~2 (2015-2018) au cours de laquelle l’énergie dans le centre de masse, la luminosité instantanée et la fréquence des collisions ont augmenté par rapport au Run~1 (2008-2013). Par conséquent, les possibilités d'analyses de processus physiques ont été largement étendues au prix d'une plus grande fluence du côté du détecteur, en particulier sur le trajectographe qui est le détecteur interne. Avec cette fluence croissante, le détecteur souffre d’une irradiation plus importante qui pourrait être à l’origine de problèmes de performance. De plus, le détecteur vieillit avec l'irradiation, entraînant une modification de certaines de ses caractéristiques. Par conséquent, il est très important de surveiller de près le détecteur, afin de conserver des performances stables et d'éviter tout impact négatif sur les analyses de physique. Dans les sections suivantes, je traiterai de deux groupes d’études sur lesquelles j’ai travaillé dans le cadre du trajectographe.

La physique des particules est décrite par le modèle standard dont la dernière pièce, le boson de Higgs, a été découverte en 2012 par les collaborations CMS et ATLAS. Bien que le mo\-dèle standard soit maintenant complet et décrive en général très bien les phénomènes physiques, il souffre de plusieurs défauts. Ce problème nous pousse à croire que le mo\-dèle standard est une théorie effective à basse énergie d’une théorie plus fondamentale à déterminer. Au fil des ans, de nombreuses théories ont été proposées et l'une d'entre elles, appelée supersymétrie, a suscité un intérêt particulier en raison de sa capacité à répondre à de nombreuses lacunes du mo\-dèle standard.

La supersymétrie introduit un nouveau partenaire pour chaque particule de modèle standard et, par conséquent, des recherches approfondies sur ces particules ont été et sont encore actuellement effectuées par la collaboration CMS, ainsi que par d’autres colla\-borations. La particule qui nous intéresse dans le cadre de cette thèse est le partenaire supersymétrique du quark top, le stop, qui devrait avoir une masse inférieure à environ 1~TeV en supersymétrie naturelle~\cite{Martin:1997ns, Barbieri:1987fn, Papucci:2011wy} et donc être accessible aux énergies du LHC. Aucun signe de l'existence de stop n'a été observé au Run~1~\cite{website:SUSYresRunI}, mais l'augmentation de la luminosité ainsi que l'énergie dans le centre de masse au Run~2 nous permettent de sonder des masses de stop au-delà de l'exclusion du Run~1.

\section{Dispositif expérimental}


La description du  détecteur Compact Muon Solenoid est donnée dans le premier chapitre, Chapitre~\ref{sec:detch}, avec une brève introduction du Large Hadron Collider~(LHC). Ce chapitre se concentre sur le trajectographe à pistes de silicium montré  à la Fig.~\ref{fig:figures/cmsTracker2}, dont la compréhension approfondie est requise pour les chapitres suivants. Ce chapitre présente également la reconstruction des objets physiques correspondant aux particules traversant le détecteur. 

    \insertFigure{figures/cmsTracker2}
                 {0.9}
                 { Schéma de la vue longitudinale de la moitié supérieure du trajectographe à pistes de silicium CMS et de la disposition de ses partitions. L'étoile représente le point de interaction. Les modules en bleu sont en stéréo, alors que les modules mono sont en noir~\cite{Chatrchyan:2014fea}.}

\section{Étude des particules hautement ionisantes dans le trajectographe de CMS}

Dans le Chapitre~\ref{sec:HIPch}, je me suis intéressée aux particules hautement ionisantes~(HIP) dans le trajectographe à pistes de silicium. Déjà avant le démarrage du Large Hadron Collider, les particules hautement ionisantes ont été étudiées et identifiées comme pouvant causer un temps mort dans l'électronique frontale, entraînant une inefficacité dans le trajectographe à pistes de silicium. Lors les tests en faisceau des modules du trajectographe, il avait été constaté qu'en diminuant la valeur de la résistance du convertisseur de l’électronique frontale, le temps mort pouvait être diminué~\cite{Bainbridge:2004jc} comme indiqué dans le Tableau~\ref{tab:tableDeadtimes2}, et le design de l'électronique avait donc été ajustée pour atténuer ce problème. En 2015-2016, lorsqu'une augmentation de l'inefficacité de reconstruction des hits dans le trajectographe a été observée pouvant aller jusqu'à 7\%, les HIP ont immédiatement été identifiés comme une explication possible. 

J'ai étudié l'effet des HIP pour la première fois avec des données de collisions LHC. Les  événements de collision enregistrés en 2016 dans un format de données spécial dans lequel aucune soustraction ni suppression n'ont été appliquées au niveau de l'électronique arrière, donnant accès aux informations complètes sur tous les canaux. Cette étude m'a permis de confirmer que le HIP induit une charge importante sur quelques canaux et a forcé les canaux restants connectés à la même puce électronique frontale, la puce APV, vers des charges plus faibles jusqu'au moment où le signal est trop petit pour être converti en lumière comme on peut l'observer sur la Fig.~\ref{fig:figures/peakinmodule}. Lorsqu'on atteint ce niveau sans lumière émise, on observe également une réduction des différences entre les charges de tous les canaux d'un APV, en excluant les canaux lisant une charge associée du HIP. A partir de ces données, j'ai pu mesurer le taux d'événements HIP, c'est-à-dire  le rapport entre  le nombre d'événements ayant une interaction HIP et  tous les événements. Ce taux est de 4 $\times 10^{-3} $ pour la première couche de Tracker Outer Barrel~(TOB), trop bas pour être responsable des inefficacités observées en 2015 et 2016. J'ai également évalué le temps mort pour cette couche à environ 250~ns. Il est du même ordre que les temps morts évalués dans des études antérieures effectuées lors de tests en faisceau à PSI, à savoir un temps mort moyen de 100~ns et un temps mort  maximal de 275~ns pour les modules TOB, respectivement.

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
Type de capteur et $R_{inv}$~[$\Omega$] & $\Gamma_{mean}$~[ns]  & $\Gamma_{max}$~[ns] \\
\hline
\hline
TIB 100 $\Omega$ & 99.5 $\pm$ 12.0 & 200 $\pm$ 25 \\
TIB 50  $\Omega$ & 69.6 $\pm$ 9.4 & 250 $\pm$ 25 \\
TOB 100  $\Omega$ & 122.5 $\pm$ 12.6 & 275 $\pm$ 25 \\
TOB 50 $\Omega$  & 100.5 $\pm$ 3.6 & 275 $\pm$ 25 \\
\hline
TIB $\Gamma_{mean}(50~\Omega )/\Gamma_{mean}(100~\Omega)$ &  0.70 $\pm$ 0.13  & \\
TOB $\Gamma_{mean}(50~\Omega )/\Gamma_{mean}(100~\Omega)$ &  0.82 $\pm$ 0.09 & \\
\hline
\end{tabular}
\caption[Table caption text]{Le temps mort moyen~($\Gamma_{mean} $) et le temps mort maximal~($\Gamma_{max}$) de la puce APV induits par les événements HIP pour les lignes de base~(i.e. la médiane calculées sur l'ensemble des 128 pistes lues par une puce APV) qui sont entièrement supprimées~($\sigma_{raw} <1 $~ADC). Les temps morts ont été évalués pour deux géométries de module différentes~(TIB et TOB) ainsi que pour deux valeurs de résistance de convertisseurs~(100 et 50~$\Omega$). Ces résultats ont été obtenus avec des données de tests en faisceau à PSI avant le début de l'exploitation du LHC~\cite{Bainbridge:2004jc}.}
\label{tab:tableDeadtimes2}
\end{center}
\end{table}


    \insertFigure{figures/peakinmodule}
                 {0.47}
                 {Exemple de distributions du signal vu par les 512 pistes (strip) d'un module, sous format raw digis~(en rose), après soustraction du piédestal~(en bleu), après soustraction de la ligne de base~(en rouge) et après soustraction des amas~(en vert). Chaque ensemble de 128 pistes est lu par une puce APV. Le troisième APV dans le module montre un comportement induit par un événement HIP: une faible variation de charge pour les raw digis et un grand signal observé pour quelques canaux.}       % Width, in fraction of the whole page width

Au cours de l'été 2016, la plus grande source d'inefficacité de reconstruction des hits dans le trajectographe a été identifiée et corrigée en modifiant la configuration de la puce APV. Selon les conditions de run, l'inefficacité de le reconstruction des hits après correction de la configuration APV est d'environ moins de 1\%. Suite à cela un nouvel lot de données a été enregistré afin d'étudier l'effet HIP de manière plus détaillée. En raison des conditions de prise de données, ces nouvelles données ont permis de mesurer la probabilité d'avoir un HIP dans un environnement plus propre. La probabilité d'avoir un HIP ($p_{HIP}$) a été calculée par interaction proton-proton, c'est-à-dire que la fraction d'événements avec un HIP ($f_{HIP}$) été divisée par le taux maximal d'interactions simultanées (peak pileup: PU), $p_{HIP} = f_{HIP}/PU$ , afin de pouvoir appliquer cette probabilité à toute configuration de structure des faisceaux du LHC. La probabilité d'avoir un HIP dans le trajectographe à pistes de silicium est représentée sur la Fig.~\ref{fig:figures/probPerPU2} et les mesures varient entre ~10$^{-4} $ et $ 10^{-3}$\% selon sur la position dans les différentes partitions du trajectographe. Les probabilités d'avoir un HIP, déjà évaluées par le passé à partir de simulations et utilisant des données de tests en faisceau, ont été dérivées par particule et ne peuvent donc pas être facilement comparées à la mesure actuelle. De plus, lors des tests en faisceau, la composition des particules et leurs spectres en énergie étaient différents par rapport à l'environnement CMS.

    \insertTwoFigures{figures/probPerPU2}
                 {figures/probFinalLayerPU} % Filename = label
                 {figures/probFinalPURings} % Filename = label
                 {0.47}       % Width, in fraction of the whole page width
                 { Probabilité moyenne d'avoir un événement HIP par unité du pileup~(PU) pour les couches du TIB et du TOB (aussi bien sur la figure  de gauche que de droite) et pour les roues (à gauche) ou les anneaux (à droite) des partitions TID et TEC du trajectographe de silicium. Ces probabilités ont été calculées à partir du run 281604 enregistré en 2016 (2$^e$ étude des HIP).}


La probabilité d'avoir un HIP ne peut pas être diminuée, mais nous pourrions chercher si le temps mort et par conséquent l’inefficacité de reconstruction du hits des traces pourraient eux être réduits. Une option permettant de réduire le temps mort a été identifiée et étudiée dans le passé ~\cite{website:hitLoss}. Cette option permet de maximiser les données après soustraction du piédestal\footnote{Le piédestal est l’activité moyenne sur une piste quand aucune particule n’est présente.} afin de réduire le risque que les charges des canaux soient décalées trop bas, au-delà de la plage mesurable. En réalité dans le mode de prise de données standard, c'est le piédestal moins un certain décalage fixe qui est soustrait par l’électronique back-end. Le choix de ce décalage pourrait être optimisé, mais il a été constaté que cette option ne fait qu’accroître la multiplicité des ``faux'' amas  sans améliorer l’efficacité de reconstruction des hits. De plus, cette option réduit la plage dynamique, ce qui se traduit par des charges plus importantes à tronquer plus rapidement. Cependant, ce test a été effectué avec l'ancienne configuration de la puce APV et il pourrait être utile de le répéter maintenant.



Une probabilité d'avoir un HIP mesurée de $10^{-4}-10^{-3}$\% signifie que dans le cas d'un temps mort de 250~ns (obtenu grâce à la première étude de cette thèse), d'un espacement de 25~ns entre les paquets des particules du faisceau, la puce APV ne serait jamais pleinement efficace uniquement si le pileup était de l'ordre de $10^4 - 10^5$. Le pileup actuel au cours de l'été 2018 est de l'ordre de 40 interactions par croisement de faisceau et donc loin du scénario d'une puce totalement inefficace. L'inefficacité de reconstruction des hits résultant des HIP a récemment été calculée en utilisant un temps mort de 250~ns et la probabilité d'avoir un HIP mesurée, elle est de l'ordre de 0.1-1\% pour un pileup de 30 comme pour le run représentatif utilisé pour la mesure de l'efficacité de reconstruction des hits en 2018. Cet ordre de grandeur est similaire à l'inefficacité mesurée en 2018. Par conséquent, la principale source de l’inefficacité mesurée semble désormais provenir de l’effet HIP. Cette inefficacité n'est pas prise en compte lors de la simulation des événements.


Le deuxième ensemble de données m'a également permis d'étudier la charge et la multiplicité des amas, présentées à la Fig.~\ref{fig:figures/avClusterMultiplicitySecondT2}, en présence d'un événement HIP ou juste après. J'ai découvert que la multiplicité de faux amas augmente après l'événement HIP par rapport à un événement standard non influencé par un HIP. Cependant, la probabilité d'avoir un HIP est faible et, par conséquent, en moyen sur le run, la multiplicité de faux amas résultant du HIP est du même ordre de grandeur que la multiplicité de faux amas en l'absence de HIP, le nombre  étant deux ordres de grandeur inférieur au cas du out-of-time pileup. J'ai observé que les faux amas induits par le HIP proviennent de distorsions de la ligne de base. Pour la première couche du TOB, j'ai également estimé une limite inférieure sur la probabilité qu'une trace soit reconstruite avec au moins un faux amas provenant d'un événement HIP. Cette probabilité est de 0.002 \% et donc négligeable. Ces faux amas ne sont pas non plus inclus dans la simulation. Mais comme on l’a vu, leur impact est négligeable, il est donc raisonnable de les omettre de la simulation.


    \insertTwoFigures{figures/avClusterMultiplicitySecondT2}
                 {figures/avClusterMultiplicitySecond} % Filename = label
                 {figures/avClusterChargeSecond} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 {Nombre d'amas moyenne (à gauche) et charge moyenne portée par les amas (à droite) en fonction du numéro d'identification du croisement de faisceau pour le run 281604. Le premier triangle rose représente l’événement HIP, les triangles suivants représentes les événements successifs (post HIP), tandis que les carrés bleus sont pour les événements non affectés par un HIP. }




Malheureusement, en raison des conditions de prise de données utilisée pour la 2$^{eme}$ étude, il était impossible de mesurer du temps mort. Les premières données ont fourni une meilleure occasion de mesurer le temps mort, mais avec la difficulté de déterminer précisément le temps de l'occurrence du HIP. Il n’existe pas d’options simples de conditions de prise de données permettant de mesurer le temps mort à l’avenir. Dans ce paragraphe, je propose deux idées plus complexes de prises de données qui pourraient être envisagées. La première option consisterait à organiser la prise de données dans laquelle les événements seraient enregistrés tous les 25~ns pendant au moins 15 croisements de paquets, sans respecter aucune règle de déclenchement, afin de pouvoir suivre un HIP donné dans le temps. De plus, il serait nécessaire de reconsidérer la stratégie d’analyse. Par exemple, comme nous ne serions plus intéressés par la mesure de la probabilité d'avoir un HIP, nous pourrions repérer l’événement HIP en présence d’un grand pic, qui n’apparaît que pour quelques instants et devrait donc mieux déterminer le temps de l’événement HIP. Mais cette approche pourrait surcharger le système d'acquisition de CMS et il faudrait donc évaluer si une telle prise de données serait raisonnable et comment nous pourrions éventuellement éviter la surcharge. La deuxième option serait d'avoir un structure spéciale de remplissage du faisceaux du LHC et de violer partiellement les règles de déclenchement de CMS. Dans un tel scénario, nous aurions besoin de trains contenant uniquement deux paquets et pour chaque train, nous aurions besoin d'un intervalle de temps différent entre les deux paquets: pour le premier train les deux paquets seraient séparés par 25~ns, pour le second par 50~ns, pour le troisième par 75~ns, etc. Grâce à de telles données, nous aurions le temps de l'événement HIP fixé par le premier croisement du train et le second, nous permettrait de mesurer l'efficacité de reconstruction des hits. Le temps mort serait obtenu  comme l'intervalle de temps entre deux croisements de paquets d'un  même train pour lesquels la même efficacité de hit est mesurée. Pour ces deux propositions, il serait nécessaire de s'assurer que les faux amas issus des distorsions de la ligne de base ne sont pas considérées comme de bons amas lors de la reconstruction  des traces et que, par conséquent, les faux amas n'augmentent pas artificiellement l'efficacité.


Pour future mise à niveau du trajectographe à pistes de silicium dans le cadre du projet High Luminosity LHC (HL-LHC), nous devons prêter attention à l’effet HIP dès la conception. Idéalement, il serait souhaitable que l’électronique soit conçue de telle manière que si une charge importante est lue par un canal, cela n’affecte pas les autres canaux appartenant à la même puce comme c’est le cas actuellement. La probabilité d'avoir un HIP calculée dans cette thèse est liée à la géométrie du module et à sa distance par rapport au point d'interaction et ne peut donc pas être facilement extrapolée à  un futur détecteur. En supposant que le trajectographe resterait le même et pour un pileup d'environ 200 interactions par croisement de paquets, le taux de HIP par puce pourrait être de l'ordre de 10$^{-2}-10 ^{-1}$\% . En réalité, le détecteur sera mis à niveau et, par conséquent, la probabilité d'avoir un HIP et le temps mort induit changeront en fonction de la conception des modules du trajectographe et de l’électronique de lecture.

\section{Amélioration de la simulation du trajectographe et mesure de la diaphonie}



Le troisième chapitre, Chapitre~\ref{ch:simu}, se concentre sur la simulation du trajectographe à  pistes en silicium de CMS et sur les paramètres de trajectographe utilisés dans la simulation afin de fournir des résultats réalistes. Ces paramètres changent avec les conditions de fonctionnement du trajectographe, par ex. la température, mais évoluent également avec le vieillissement résultant des dommages causés par le rayonnement, par exemple la diaphonie (``cross talk''), c'est-à-dire la charge partagée avec les pistes voisines comme le montre la Fig.~\ref{fig:figures/crossTalk2}. La majorité de ces conditions n’ayant jamais été mise à jour depuis le début du Run~1, nous avons donc décidé de réviser la simulation et d’étudier l’impact des paramètres obsolètes sur la simulation des amas dans le trajectographe. J'ai découvert que le changement de conditions (à l'exception du bruit et des gains) a un impact négligeable sur les propriétés des amas dans de nombreux cas, mais le changement des paramètres de la diaphonie affecte largement la largeur de l'amas et la charge de la piste collectant le signal maximal servant de graine à la formation de l'amas.

    \insertFigure{figures/crossTalk2} % Filename = label
                 {0.5}       % Width, in fraction of the whole page width
                 {Un schéma de partage de charge entre pistes voisines. }
                 %{ A schema of charge sharing between neighboring strips. }


Après avoir identifié que les paramètres de la diaphonie provoquent des écarts importants dans les distributions de forme des amas entre les données et la simulation, comme le montre la Fig.~\ref{fig:figures/seedwidthTOBXT2}, nous avons utilisé des données correspondant au passage de muons cosmiques, dans le détecteur  pour mesurer les paramètres de la diaphonie. Comme pour les études des HIP, aucune soustraction ni suppression de charge de canal n’ont été appliquées au niveau de l’électronique back-end. Dans ces données cosmiques, j'ai remarqué que les paramètres de la diaphonie évoluent en fonction du moment où la particule arrive dans un module donné. Par conséquent, la diaphonie doit être mesurée au bon moment, c'est-à-dire comme si une particule provenant de l'interaction proton-proton atteint un module donné. Ceci est particulièrement difficile pour des muons cosmiques arrivant de façon aléatoire.

J'ai mesuré que la diaphonie diminuait pour toutes les géométries de module dans la partie centrale de CMS (ou tonneau) par rapport à la mesure précédente. Les paramètres nouvellement mesurés ainsi que les paramètres actuels utilisés dans la simulation sont indiqués dans le Tableau~\ref{tab:measuredXtalk2}. Le partage de charge avec les premières pistes voisines a diminué d'environ 18-27\%, le changement étant plus important pour les géométries plus proches du point d'interaction, c'est-à-dire avec une plus grande fluence et, par conséquent, des dommages plus importants. Le partage de charge avec les deuxièmes pistes voisines a diminué d'environ 24\%. En raison des conditions de déclenchement, il n'y avait pas suffisamment de statistiques pour mesurer les paramètres de la diaphonie dans les disques~(TID) et les bouchons du trajectographe~(TEC). Pour déterminer les paramètres de la diaphonie dans ces partitions, j'ai corrigé les anciens paramètres de la diaphonie en fonction du changement observé des paramètres dans le tonneau et tenant compte des comparaisons entre  données et simulation de la charge moyenne des amas dans les événements de collision. Les résultats des mesures de la diaphonie sur les disques et les bouchons sont résumés dans le Tableau~\ref{tab:measuredXtalkTODTEC2}. En mettant à jour les paramètres de la diaphonie dans la simulation, nous avons découvert que les nouvelles mesures améliorent largement la description de la forme des amas dans les données par simulation, comme illustré à la Fig.~\ref{fig:figures/widthTOBXTm2}.

    \insertTwoFigures{figures/seedwidthTOBXT2} % Filename = label %TDO continue here
                 {figures/clusterwidthTOBl1to4XT}
                 {figures/clusterseedchargeRescaledTOBl1to4XT} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 {Distributions de la largeur des amas (à gauche) et de la charge portée par la piste collectant le plus de signal dans l'amas (à droite) pour la géométrie OB2. Les données de collision sont représentées par les points noirs, différentes valeurs de la diaphonie $XT$ sont utilisées dans la simulation (chaque set correspondant à une couleur différente). Le premier des trois nombres $XT$ correspond à la fraction de charge induite sur la piste principale, les deuxième et troisième nombres représentent les fractions de charge induites sur les premiers et seconds voisins, respectivement. Les distributions simulées sont renormalisés au nombre d'amas dans les données. Les graphique inférieurs représentent le rapports des distributions des données par la simulation.}

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
Géométrie & Type & $x_{0}$ & $x_{1}$ & $x_{2}$ \\
\hline
\hline
IB1 & nouvelle mesure & $ 0.836 \pm 0.009 $ & $0.070 \pm 0.004 $ & $0.012 \pm 0.002 $ \\
IB1 & simulation & $ 0.775 $ & $ 0.096 $ & $0.017 $  \\
\hline
IB2 &  nouvelle mesure & $0.862 \pm 0.008 $ & $0.059 \pm 0.003 $ & $0.010 \pm  0.002 $  \\
IB2 &  simulation &  $0.830 $ & $0.076 $ & $ 0.009$   \\
\hline
OB2 &  nouvelle mesure & $0.792 \pm 0.009 $ & $0.083 \pm 0.003 $ & $0.020 \pm 0.002$  \\
OB2 &  simulation &   $0.725 $ & $0.110 $ & $ 0.027 $  \\
\hline
OB1 &  nouvelle mesure &  $0.746 \pm 0.009 $ & $0.100 \pm 0.003 $ & $0.027 \pm 0.002 $  \\
OB1 &  simulation &  $0.687 $ & $0.122 $ & $ 0.034 $ \\
\hline
\end{tabular}
\caption[Table caption text]{Valeurs de la diaphonie mesurées en 2018 comparées aux anciennes mesures de diaphonie utilisées actuellement pour la simulation des géométries du tonneau. }
\label{tab:measuredXtalk2}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
Géométrie  & Type & $x_{0}$ & $x_{1}$ & $x_{2}$ \\
\hline
\hline
W1a &  nouvelle mesure & 0.8571 & 0.0608 & 0.0106 \\
W1a &  simulation & 0.786 & 0.093 & 0.014 \\
\hline
W2a &  nouvelle mesure & 0.8861 & 0.049 & 0.008 \\
W2a &  simulation & 0.7964 & 0.0914 & 0.0104 \\
\hline
W3a &  nouvelle mesure & 0.8984 & 0.0494 & 0.0014 \\
W3a &  simulation & 0.8164 & 0.09 & 0.0018 \\
\hline
W1b &  nouvelle mesure & 0.8827 & 0.0518 & 0.0068 \\
W1b &  simulation & 0.822 & 0.08 & 0.009 \\
\hline
W2b &  nouvelle mesure & 0.8943 & 0.0483 & 0.0046 \\
W2b &  simulation & 0.888 & 0.05 & 0.006 \\
\hline
W3b &  nouvelle mesure & 0.8611 & 0.0573 & 0.0121 \\
W3b &  simulation & 0.848 & 0.06 & 0.016 \\
\hline
W4 &  nouvelle mesure & 0.8881 & 0.0544 & 0.0015 \\
W4 &  simulation & 0.876 & 0.06 & 0.002 \\
\hline
W5 &  nouvelle mesure & 0.7997 & 0.077 & 0.0231 \\
W5 &  simulation & 0.7566 & 0.0913 & 0.0304 \\
\hline
W6 &  nouvelle mesure & 0.8067 & 0.0769 & 0.0198 \\
W6 &  simulation & 0.762 & 0.093 & 0.026 \\
\hline
W7 &  nouvelle mesure & 0.7883 & 0.0888 & 0.0171 \\
W7 &  simulation & 0.7828 & 0.0862 & 0.0224 \\
\hline
\end{tabular}
\caption[Table caption text]{ Valeurs de la diaphonie actualisées pour les anneaux du TID~(W1a, W2a, W3a) et du TEC (restant), comparées aux anciennes mesures utilisés dans la simulation. }
\label{tab:measuredXtalkTODTEC2}
\end{center}
\end{table}


    \insertTwoFigures{figures/widthTOBXTm2} % Filename = label %TDO continue here
                 {figures/clusterwidthTOBl1to4XTm}
                 {figures/clusterseedchargeRescaledTOBl1to4XTm} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 {Distribution de la largeur de l'amas (à gauche) et de la charge portée par la piste collectant le plus de signal dans l'amas (à droite) dans les données et la simulation pour la géométrie OB2, pour les paramètres de la diaphonie ($XT$) actuels (défaut, en rouge) et nouvellement mesurés (updated, en bleu). Les distributions simulées sont renormalisés au nombre d'amas dans les données. Les graphiques inférieurs représentent le rapport des données et simulation. }


Les paramètres de la diaphonie influencent profondément la forme des amas, mais pas leur charge totale. Le changement de la diaphonie pourrait faire en sorte que les amas qui étaient précédemment légèrement au-dessus du seuil de clustering soient à présent en dessous et ne soient donc plus reconstruits, et vice versa. De plus, avec la modification des paramètres de la diaphonie, la position de l'amas et sa résolution changent lors de la simulation, entraînant de petits changements dans la reconstruction des traces. Par conséquent, l'effet d'une modification de la diaphonie peut se propager jusqu'à certaines des analyses de physique, par exemple dans les recherches de signatures de nouvelle physique qui cherchent des traces qui apparaissent tardivement ou disparaissent dans le trajectographe. L'identification des objets de physique, qui dépendent fortement du trajectographie, comme par exemple le b-tagging (identification des jets comme issus de quarks b) , peut également être influencée par un changement des paramètres de la diaphonie. L'impact sur les autres objets et analyses de physique, qui ne dépendent pas fortement du trajectographie, devrait être négligeable.


Il a été montré que les paramètres de la diaphonie évoluent en fonction de la fluence et doivent donc être réévalués et mis à jour régulièrement. De plus, des mesures plus fréquentes des paramètres de la diaphonie pourraient nous aider à comprendre pourquoi la diaphonie diminue par rapport à la mesure précédente. La littérature~\cite{Hartmann:2017gzy} indique qu'avec une fluence croissante, la capacité entre les pistes devrait augmenter et la résistance inter-pistes diminuer. Ces deux changements devraient entraîner une augmentation de la diaphonie, ce qui n’a pas été observé. Cependant, la résistance et la capacité entre les pistes ne sont pas les seuls facteurs qui influencent la formation du signal. Il existe un réseau plus complexe de capacités et de résistances qui ont un impact sur la forme de l'amas. Notez que la diaphonie a été mesurée uniquement pour le mode principal d'échantillage du signal (mode déconvolution). Il faudrait donc également la mettre à jour pour le mode ``peak''. Bien que ce dernier mode ne soit pas utilisé dans la prise de données standard, il pourrait nous aider à étudier la diminution de la diaphonie en distinguant les effets de la déconvolution des autres effets.

Les données cosmiques enregistrées en l'absence de champ magnétique, qui ont été utilisées pour la mesure de la diaphonie, ont posé plusieurs contraintes et difficultés. Tout d'abord, en raison des conditions de déclenchement, les statistiques sur les disques et les bouchons sont insuffisantes. Même si le déclenchement était re-conçu, en raison de la direction d'arrivée des cosmiques, la prise de données devrait être longue afin de collecter suffisamment de statistiques dans ces zones-là, ce qui est difficile à organiser dans le calendrier serré du CMS. Le deuxième problème important est lié à la synchronisation du trajectographe lorsqu'il échantillonne le signal collecté. Le trajectographe n'a pas de configuration de synchronisation spéciale pour les cosmiques et, par conséquent, la synchronisation des collisions est toujours utilisée. Comme la diaphonie varie en fonction du temps dans l'échantillonnage du signal, nous ne devons utiliser pour la mesure de la diaphonie que les cosmiques dont le temps d'arrivée au module donné coïnciderait avec celui d'une particule produite lors d'une collision proton-proton. Une autre ambiguïté provient du calcul du temps d'arrivée des particules, qui extrapole toutes les particules au point d'interaction, même si elles ne sont pas passées par là. Tous ces problèmes pourraient être résolus s'il était possible d'organiser une nouvelle prise de données de collision en mode spécial d'acquisition (sans soustraction ni suppression de charge) et sans champ magnétique. Mais une telle prise de données n'est pas compatible avec le programme et les priorités de CMS.


Après la modification des paramètres de la diaphonie et des conditions tels que les gains et le bruit mis à jour par les autres membres du groupe de reconstruction locale du trajectographe, la description par la simulation des amas synchronisés avec les croisements de faisceaux (``en temps'') dans les données a été grandement améliorée. Il a été identifié qu'il existe encore plusieurs paramètres qui sont obsolètes et pourraient être mis à jour à l'avenir, mais ces paramètres ne modifient pas largement la description des amas. Dans cette thèse d'une part, j'ai découvert que la simulation est simplifiée et parfois non réaliste, mais d'autre part, le développement de modèles plus sophistiqués n'améliorerait pas grandement la description des amas dans les données par simulation. J'ai également constaté que certaines parties de la simulation ont un impact négligeable, à savoir la diffusion, et il pourrait être utile d'évaluer quelles parties de la simulation sont réellement nécessaires pour réduire le temps nécessaire à la simulation d'événements.

Plusieurs améliorations pourraient encore être incluses dans la simulation des amas non synchrones avec des collisions. Tout d'abord, la forme du signal a changé en raison de la modification de la configuration de la puce APV suite au problème d'inefficacités de reconstruction des hits discuté précédemment. Par conséquent, la forme du signal doit être mise à jour afin de réduire la charge simulée d'une fraction correcte. Deuxièmement, il a été montré que la diaphonie dépend du temps. Les paramètres de la diaphonie ont été dérivés pour les amas ``en temps'' et ne sont pas corrects pour les amas pas ``en temps''. Idéalement, les paramètres de la diaphonie devraient être estimés en fonction du temps d'arrivée des particules au module. Les amas pas ``en temps'' devraient également être mieux simulés, car ces amas pourraient être utilisés par l’algorithme de trajectographie pour reconstruire les traces des particules.


Pour aller plus loin avec les données cosmiques enregistrées, je propose ici quelques d’études intéressantes qui pourraient être réalisées. Dans le passé, on observait une asymétrie gauche-droite dans le partage des charges. Cet effet pourrait aussi être étudié avec les données que j'ai utilisées. De plus, il est possible d'étudier les propriétés de la diaphonie et d'amas en fonction de la position où la trace croise le plan des pistes, à proximité ou à distance de la piste. Dans le passé, il a également été observé qu’il existe une évolution de la charge portée par la piste de plus grande charge dans l'amas en fonction du numéro de la piste dans une puce APV, cette étude pourrait être répétée avec ces données. Toutes ces études pourraient aider à mieux comprendre la formation du signal, les caractéristiques des capteurs telles que les non-uniformités dans le champ électrique, ainsi que les modifications des propriétés des capteurs résultant de leur irradiation.

Dans le futur trajectographe pour le HL-LHC, le formation des amas sera complètement différente, seules les informations binaires de la piste/macro-pixel seront envoyées. Par conséquent, la charge de la piste de charge maximale et la charge totale de l'amas ne seront plus disponibles, seule la largeur de l'amas sera connue. Comme la largeur de amas dépend de la diaphonie, il sera également nécessaire de mesurer la diaphonie dans le nouveau trajectographe. De plus, il sera important de déterminer l'impact de la diaphonie sur le passage de seuil entre 0 et 1 pour la charge de la piste/macro-pixel, afin de fixer correctement le seuil et le surveiller au cours du temps.

\section{Recherche du partenaire supersymétrique du quark top}

Le Chapitre~\ref{sec:SUSYch} introduit le Modèle Standard~(MS) et la Supersymétrie (SUSY). Malgré sa capacité à bien décrire la majorité des phénomènes physiques observés, le modèle standard de la physique des particules souffre de plusieurs inconvénients tels que le problème de la hiérarchie ou l’absence d’un candidat pour la matière noire. En raison de ces lacunes, des théories au-delà du MS ont été proposées et l'une d'entre elles, la supersymétrie, est devenue la plus prometteuse en raison de sa capacité à traiter une grande partie des problèmes du MS. 

Dans cette thèse, j'ai présenté au Chapitre~\ref{sec:stopch} une recherche du partenaire supersymétrique du quark top, le stop, avec les données de CMS du Run~2. Cette recherche vise la production de paires de stops, avec trois possibilités différentes pour les désintégrations des stops: 1) les deux stops se désintègrent chacun un quark top et un neutralino (Fig.~\ref{fig:figures/stopdecays3} en haut à gauche), 2) la désintégration des deux stops en un quark et un chargino (Fig.~\ref{fig:figures/stopdecays3} en haut à droite), 3) chaque stop se désintègrent différemment comme un mélange des deux cas précédents (Fig.~\ref{fig:figures/stopdecays3} en bas). Dans tous les cas, les états finaux du signal ciblé contiennent un lepton, des jets et de l'énergie transverse manquante.

    \insertThreeFigures{figures/stopdecays3}
                 {figures/T2tt} % Filename = label
                 {figures/T6bbWW} % Filename = label
                 {figures/T4tbW}
                 {0.45}       % Width, in fraction of the whole page width
                 { Les diagrammes de modèles simplifiés pour la production direct de paires de stops. Dans le diagramme en haut à gauche, chaque stop se désintègre en $t  \tilde{\chi}^{0}_{1}$ (T2tt), tandis qu'en haut à droite, il se désintègre en $ b \tilde{\chi}^{\pm}_{1} $ (T2bW). Dans le diagramme en bas, la désintégration mixte de la paire de stops $\bar{t} \tilde{\chi}^{0}_{1} b \tilde{\chi}^{+}_{1}$ est considérée~\cite{website:SUSYdiagrams}. }


J'ai été impliquée dans trois versions publiques de cette recherche: une basée sur les données enregistrées en 2015 correspondant à une luminosité intégrée $\int{\mathcal{L}} $ de 2.3~fb$^{-1}$~\cite{Sirunyan:2016jpr}, la seconde basée sur les données enregistrées début 2016 ($\int{\mathcal {L}} = 12.9 $~fb$^{-1} $)~\cite{CMS:2016vew} et la dernière correspondant à $ \int{\mathcal {L}} = 35.9 $ ~ fb$^{-1} $ collecté pendant toute la période de prise de données proton-proton de 2016~\cite{Sirunyan:2017xse}. J'ai été principalement impliquée dans la dernière analyse, où j'étais responsable de l'estimation de l'un des bruits de fond de l'analyse constitué des processus ttZ et WZ, dans lesquels un boson Z se désintègre en deux neutrinos. Je n’ai pas seulement estimé ce bruit de fond, mais j’ai également fourni les incertitudes systématiques sur ce bruit de fond. Les résultats peuvent être vus dans les Tableaux~\ref{tab:YZnunu} et~\ref{tab:SysZnunuSum} du Chapitre~\ref{sec:stopch}. Dans cette thèse, j'ai également exploité une technique de marquage de jets boostés provenant d'un boson W et j'ai montré que le gain de mise en œuvre d'une telle technique augmente avec la luminosité intégrée.


Les recherches pour la production de paires de stops dans différents états finaux avec 0, 1 ou 2 leptons avaient déjà été effectuées avec les données Run~1 sous l'hypothèse de différents modes de désintégration. Ces analyses excluent dans le cadre de scénarios simplifiés avec des stops se désintégrant en un quark top et un neutralino des masses de stops jusqu'à environ 755~GeV pour une masse de neutralino inférieure à 200~GeV. Avec l'augmentation de l'énergie dans le centre de masse puis de la luminosité intégrée au Run~2, il est possible de sonder davantage les masses de stop. Comme on peut le voir sur la Figure~\ref{fig:figures/resultPlot2}, aucun excès n'a été observé dans les données enregistrées en 2016 et correspondant à ($ \int{\mathcal {L}} = 35.9 $~fb $^{-1} $) quand on les compare aux prédictions de bruits du fond du MS et, par conséquent, des limites d'exclusion ont été posées. Cette analyse exclut les masses de stop jusqu’à 1120 GeV pour un neutralino sans masse en termes de modèles simplifiés où les deux stops se désintègrent en un quark top et un neutralino, comme le montre la Fig.~\ref{fig:figures/limitT2tt}. Dans le cas où les deux stops se désintègrent en un quark bottom et un chargino ou dans le cas de désintégration mixte, les masses de stop ont été exclues jusqu’à 1000 GeV et 980 GeV, respectivement, comme présenté aux Fig.~\ref{fig:figures/limitT2bW2}  et~\ref{fig:figures/limitT2tb}.

    \insertFigure{figures/resultPlot2} % Filename = label
                 {0.75}       % Width, in fraction of the whole page width
                 {Nombre d'événements observés dans les données (points noirs), des estimations de bruits du fond ainsi que 3 scénarios possibles de signaux dans les 31 régions de signal de l'analyse. Le bruit du fond correspondant à un lepton perdu est représenté en vert, le bruit du fond  $ 1 \ell $ provenant du processus $ W + jets \to 1 \ell $ (c'est-à-dire pas du top) en jaune, le bruit du fond $ Z \to \nu \bar {\nu} $  en violet et la contribution $ t \bar {t} \to 1 \ell $ en rouge. Le modèle T2tt ($ \tilde{t}_{1} \to t \tilde {\chi}^{0}_{1} $) avec une masse du stop de 900~GeV et une masse du neutralino de 300~GeV est représenté par une ligne pointillée bleue. Les scénarios T2tb ($\tilde{t}_{1} \to t \tilde{\chi}^{0}_{1} /\tilde{t}_{1} \to b \tilde{\chi}^{\pm}_{1}$) et T2bW ($\tilde{t}_{1} \to b \tilde{\chi}^{\pm}_{1} $) pour une masse du stop de 600~GeV et une masse de neutralino de 300~GeV sont respectivement représentés par une ligne pointillé rose et une verte. La ligne pointillée rouge sépare les régions de signal de l'analyse  nominale et de l'analyse dédiée à la région compressée avec $\Delta m\mathrm{(stop, neutralino)<225~GeV}$. }

    \insertFigure{figures/limitT2tt}
                 {0.49}       % Width, in fraction of the whole page width
                 {Les limites d'exclusion à 95\% CL sur le modèle T2tt correspondant à une luminosité intégrée de 35.9~fb$^{-1}$. L'interprétation est fournie  dans le plan de la masse du stop par rapport à la masse du neutralino. Le code de couleur indique la limite supérieure de 95 \% CL sur la section efficace en supposant un rapport de branchement de 100\% pour $ \tilde {t}_{1} \to t \tilde{\chi}^{0}_{1} $. Les contours rouge et noir représentent respectivement les limites d'exclusion attendues et observées. La zone sous la courbe épaisse noire indique la région exclue des points de signal. }


    \insertFigure{figures/limitT2bW2} % Filename = label
                 {0.5}       % Width, in fraction of the whole page width
                 { Les limites d'exclusion à 95\% CL sur le modèle T2bW correspondant à une luminosité intégrée de 35.9~fb$^{-1}$. L'interprétation est fournie dans le plan de la masse du stop vs la masse du neutralino. Le code couleur indique la limite supérieure de 95\% CL sur la section efficace en supposant un rapport de branchement de 100\% pour $ \tilde{t}_{1} \to b  \tilde{\chi}^{\pm}_{1} $.  Les contours rouge et noir représentent respectivement les limites d'exclusion attendues et observées. La zone sous la courbe épaisse noire indique la région exclue des points de signal. }


    \insertFigure{figures/limitT2tb}
                 {0.49}       % Width, in fraction of the whole page width
                 {Les limites d'exclusion à 95\% CL sur le modèle T2tb correspondant à une luminosité intégrée de 35.9~fb $^{-1}$. L'interprétation est fournie dans le plan de la masse du stop par rapport à la masse du neutralino. Le code de couleur indique la limite supérieure de 95\% CL sur la section efficace en supposant un rapport de branchement de 50\% pour $\tilde{t}_{1} \to t \tilde {\chi}^{0}_{1} $ et 50\% pour $\tilde{t}_{1} \to b \tilde{\chi}^{\pm}_{1} $. Les contours rouge et noir représentent respectivement les limites d'exclusion attendues et observées. La zone sous la courbe épaisse noire indique la région exclue des points de signal. }



Malgré de l’exclusion du stop dans la gamme du TeV, il reste de la place pour la supersymétrie naturelle~\cite{Baer:2016bwh} et, par conséquent, l’effort de recherche des stops ne diminue pas. Selon les prévisions de la collaboration CMS, avec une luminosité intégrée de 3000~fb$^{-1} $ devant être collectée au HL-LHC, il sera possible de sonder les masses de stop jusqu'à 2~TeV~\cite{website:moriond}. Une augmentation supplémentaire de l’énergie dans le centre de masse (projet HE-LHC)  nous permettrait de sonder encore plus loin les masses de stop.


Avant de migrer vers des projets futurs, il existe plusieurs directions pour améliorer l'analyse de stop présentée dans cette thèse en vue d'une future mise à jour basée sur des données avec une luminosité intégrée plus grande. Pour l'estimation des bruits du fond, il est souhaitable d'utiliser des méthodes basées sur les données afin de minimiser la dépendance à la simulation et, par conséquent, de réduire les incertitudes systématiques. Les estimations des bruits du fond  à partir des  données sont basées sur des régions de contrôle, ces régions de contrôle doivent être définies de manière très similaire aux régions où nous cherchons le signal pour éviter les incertitudes dues aux extrapolations. Ces extrapolations reposent sur la forme des variables dans la simulation et, si elles ne sont pas bien modélisées, elles augmentent largement les incertitudes systématiques sur les bruits du fond. Du côté du signal, la simulation simplifiée d'événements n'est pas fiable dans la région du plan de masses  (m(stop), m(neutralino)) lorsque  $ \Delta m (\mathrm{stop, neutralino}) \sim m(\mathrm{top}) $ à faible m(neutralino). Cela pourrait être résolu en utilisant la simulation complète du détecteur dans cette région cinématique particulière. Ensuite, la stratégie d'analyse peut également être réoptimisée. Il est possible de réoptimiser les régions de signal en trouvant des coupures optimales spécifique pour une luminosité donnée mais également en essayant  de trouver de meilleures variables discriminantes. Une autre option consiste à utiliser des reconstructions différentes d'objets. Par exemple de nos jours, il existe une variété d'objets ciblant l'identification du boson W ou du quark top, non seulement comme un large jet unique regroupant tous les produits de la désintégration du W ou du top, mais également comme plusieurs jets complètement résolus ou des jets partiellement fusionnés. Nous pourrions également envisager de ne pas effectuer d’analyse de comptage, mais de passer à une analyse de forme d'une variable discriminante, en utilisant des techniques d’apprentissage multi-variées permettant d’établir une meilleure distinction entre le signal et le bruit du fond.


Au sein de la collaboration CMS, une grande variété de recherches SUSY est effectuée. Les stops sont recherchés dans plusieurs états finaux différents et les autres particules SUSY prédites sont également ciblées par des recherches dédiées. De nombreuses analyses recherchent SUSY dans le contexte du modèle supersymétrique minimal (MSSM), mais il existe également plusieurs recherches allant au-delà, par exemple des recherches permettant de violer la R-parité. En général, les recherches SUSY sont interprétées en termes de modèles simplifiés. De nombreux efforts sont déployés pour réinterpréter ces recherches dans des modèles plus réalistes. Une autre partie des activités est la combinaison de recherches pour atteindre un meilleur potentiel de découverte/exclusion. L'expérience CMS et en général les expériences de collisionneur ne constituent pas la seule opportunité de rechercher la supersymétrie. Par exemple, la supersymétrie peut également être étudiée par des expériences de détection directe de matière noire.


En résumé, il existe encore de nombreuses options pour une SUSY naturelle en termes d'espace de paramètres, ainsi que de nombreuses options pour la rechercher. Les expériences de collisionneur sont l'une de ces options et, avec l'augmentation de la luminosité, de l'énergie et de l'optimisation des analyses, elles offrent de grandes possibilités pour dépasser les limites actuelles et explorer davantage l'espace de phase non couvert.

%----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
