<5\% -> signal hypothesis rejected at the 95\% confidence level -> exclusion
- express p-value as the significance associated to it as the pdf is gaussian
-z=5, significance = 2.8x10-7

-LHC - profile likelihood\chapter{Stop}

\section{Introduction and motivation}

The supersymmetry was found to be the most popular extention of the Standard Model, due to its capabality to adress many shortcomings of the SM. Among others it provides solution to the naturalness probelm and provieds dark matter candidate. Supersymmetry introduces a supersymmetric partner to each SM particle, which have the same quantum numbers except of spin differing by 1/2. This chapter is focused on the production of the suppersymetric partners of the stop quarks, reffered as ``stops''~($\tilde{t}$). There are two scalar stops $\tilde{t}_{R}$ and  $\tilde{t}_{L}$ as there is left and right component of the SM fermion field. These two stops mix into mass eigenstates $\tilde{t}_{1}$ and $\tilde{t}_{2}$,  $\tilde{t}_{1}$ being the lighter one. Due to the naturalnes constraint the ligter stop should have mass in TeV range. Morover the Higss mass measurements give condition that $\sqrt{m_{\tilde{t}_{1}} m_{\tilde{t}_{2}}}$ should be around 600~GeV. In this chapter a SUSY model, in which the R-parity is conserved and the LSP is the lightest neutralino~($\tilde{\chi}^{0}_{1}$), is considered. Furthermore only direct stop pair production is assumed.

Depending on the mass difference between stop and neutralino, $\Delta m =  \tilde{\chi}^{0}_{1}$, several decay modes of the stop quark are possible. The stops can decay via two, three or four body decays to final states with b or c quarks. This chapter discribes search for top squark pair production in pp collisions at sqrt(s)=13~TeV using single lepton events~\cite{Sirunyan:2017xse}. As I was also involved in previous versions of this analysis~\cite{Sirunyan:2016jpr, CMS:2016vew}, the differences between the three analyses are briefly discussed.



-intro what we focus on

- mtoivation
	two stpos of different mass, stop1 and stop2
	short conclusion of susy chapter - light stop, 1-lep, high xsection -> basic or sth more like Alex?
	single lepton high br and low backgrounds
	targeting few posssible decay chains
	can be destinguished from backgrounds when cutting on MET, MT...
	32\% of directly produced stops decay to final states with one lepton
-signature  and possible decays
	SMS, T2TT, T2bW. T2tb, decay cascades, feynam diagrams
	r parity conservation
	

-plane od delta M
	search in delta M plane


-general intro
	- I worked on more versions of analyses, but only one introfuced and than the differences, and then some chosen personal contribution

-delta M around top mass challenging kinematics -> looks like SM tt -> this region is called stealthy region
-for t2bW when W becomes on-shell also difficult kinematics

-analysis is kind of general, one search targeting all signals (~except of corridor)

\subsection{Statistical methods}

CMS uses modified frequentis method reffered as ``CLs'' method~\cite{Read:2002hq, Junk:1999kv, Cowan:2010js, CMS-NOTE-2011-005} to compute excusion limits
Define tw hypoyhesis null hypothesis H0n background only and denote B as background yield
Define H1 alternative hypothesis, where b+mu s are signal and background yields and mu is the signal sternght -> mu=0 for background only and 1 fors+b hypothesis
The statistics for CLs method is burdened by many systematical uncertainties which are treated as nuisiance parameters $\Theta$ -> then background and signal expectations are function of theta s(theta), b(theta)


To compute an observed limit we can buil a likelihood function $\mathcal{data|\mu, \theta}$

\eq{likelihood}
{
\mathcal{data|\mu, \theta} = Poisson(data| \mu s(\theta) +b(\theta)) p(\tilde{\tehta}|\theta),
}

where $p(\tilde{\theta}\theta)$ is the pdfs for a nuisicance parameter $\theta$ with $\tilde{\theta}$ being the default value of the nuisance parameter and data for this purpose ferref to the information about observed data and expected signal and background yields. In case of binned Likelihood the term $Poisson(data| \mu s(\theta) +b(\theta))$ can be expressed as


\eq{binnedlikelihood}
{
Poisson(data| \mu s(\theta) +b(\theta)) p(\tilde{\theta}|\theta) = \prod_{i} \frac{\mu s_{i}+b_{i}}{n_{i}!} e^{-\mu s_{i}-b_{i}},
}

which is a product  of Poisson probabilities to observe $n_{i}$ events in bin $i$. Having the Likelihood function, the compatibility of data with background only or background plus signal hypothesis can be tested with help of test statistics $\tilde{q}_{\mu}$ which is in for of the profile likelihood ratio

\eq{pLR}
{
\tilde{q}_{\mu} = -2 \mathrm{ln } \frac{ \mathcal{L}(data| \mu , \hat{\theta}_{\mu}) } {\mathcal{L}(data| \hat{\mu} , \hat{\theta})}, 0 \leq \hat{\mu} \leq \mu ,
}

where $\mu$ is a free parameter, $\hat{\theta}_{\mu}$ are conditional maximum likelihood estimators of parameters $\theta$ given the parameter $\mu$ and measured data. The $\hat{\mu}$ and $\hat{\theta}$ are the parameter estimators at the global mximum of likelihood. The condition $\hat{\mu} \geq 0 $ express that the rate of signal cannot be negative and $\hat{\mu} \leq \mu $ is constraint to consider only one-sided confidence interval 
	  
Once having the masured data, the observed value of profile likelihood ratio~\ref{pLR} $\tilde{q}_{\mu}^{obs}$ can be computed and the maximum lakelihood estimators of $\theta$ best describing the observed data can be evaluatedi for both background only and background plus signal hypothesis. The CLs method defines two p-values, the first one is $p_{\mu}$ testing the compatibility of observation with signal plus background hypothesis and the second testing the compatibility of observation with background only hypothesis. The CLs for given signal strenght $\mu$ is then defined as

\eq{cls}
{
CL_{s}(\mu) = \frac{p_{\mu}}{1-p_{b}},
}

where $p_{\mu}$ can be writes as

\eq{pmu}
{
P(\tilde{q}_{\mu} \geq \tilde{q}_{\mu}^{obs}|s+b)
}

and $1-p_{b}$ as

\eq{pb}
{
P(\tilde{q}_{\mu} \geq \tilde{q}_{\mu}^{obs}|b).
}

When $\mu$ is set to one and $\mathrm{CL_{s}} \leq \alpha $ where in case of exclusion limits $\alpha = 0.05$ the signal plus background hypothesis is excluded at $1-\alpha$ (=95\%) CLs confidence level. In the case of SMS the $\mu$ is not fixed to one and therefore the exclusion limits are set on the cross section times branching ratio of given SMS model. In such procedure the signal strength $\mu$ starts at zero and it is increased up to the point where CLs = 0.05. If for a given signal point the cross section is limited to a lower value than the theoertical cross section, the signal point is excluded. The contour line is drown at the place where limit on cross section is equal to the theoretical cross section.

The expected limits can be determined by similar method using generated background only pseudo-data instead of observed data. 

Assuming that the test statistics has Gaussian tail  the p-value can be converted to the significance $Z$ with help of convention

\eq{significance}
{
 p = \int_Z^{\infty} \frac{1}{\sqrt{2\pi}} e^{-x^{2}/2} dx,
}

where if considering backgroun only hypothesis, the significance of 5 standard deviations corresponds to $p_{b} = 2.8 \times 10^{-7} $ suggest that the background only hypothesis is excluded at $5 \sigma$ in favour of backgroun plu signal hypothesis. %TODO check that


-significance -> for W-tagging

-HO background only hypothesis (null hypothesis) -background
--H1 alternative hyothesis - signal
-discovery reject H0 in favour of H1
-exclusion reject H1 in favour of H0
-step 1 define null and alternative hypothesis
-step2 define test statistics undr the null hypothesis
-from observation reject of accept null hypothesis
-definition of thest statistics
	N= mu S + B
	test stat Q = -2ln (L(H0)/L(H1))-> likelihood ratio
- pvalue is measure of the icompatibility of the date with tested hypothesis
-when testing s+b hypothesis alpha = 5\%. p(S+B)<5\% -> signal hypothesis rejected at the 95\% confidence level -> exclusion
- express p-value as the significance associated to it as the pdf is gaussian
-z=5, significance = 2.8x10-7

-LHC - profile likelihood
-CLS~\cite{Read:2002hq, Junk:1999kv}

\subsection{Signal topologies}

The preseneted analysis focus on the kinematic region where $\Delta m > m_W+m_b$ and on three different decay modes of the stop pair.  All modes lead to states with two b-jets, two W-bosons and two neutralinos, but the kinematics differ depending on the decay mode and $\Delta m$. The $\Delta m$ plane is shown in Fig.~\ref{fig:figures/dmplane}. In the part of the plane where $\Delta m < m_t$, often reffered as ``compressed spectra'' region, the decay producs are soft and often not reconstructed. On the other hand when the $\Delta m$ is large, boosted topologies can be expected. 

    \insertFigure{figures/dmplane} % Filename = label
                 {0.99}       % Width, in fraction of the whole page width
                 { dm plane ~\cite{Aad:2014kra}. }

In this analysis thei targeted final states are with one leptonically and one haronically decaying W-boson, resulting in one charged lepton in final state. The advange of this one lepton channel is its relatively high branching ratio, around 32\% of directly produced stop pairs decay to final states with one lepton, and low occurance of the Standard model backgrounds. 

The first of the three considered decay chains of the stop pair shown in the left part of Fig.~\ref{figures/stopdecays} is reffered as ``T2tt'', where both stops decay to top quark and neutralino, followed by decay of each top quark to W-boson and b-quark:

\eq{t2tt}
{
    \tilde{t}_{1} \bar{\tilde{t}}_{1} \to t \bar{t} \tilde{\chi}^{0}_{1} \tilde{\chi}^{0}_{1} \to b \bar{b} W^{+} W^{-} \tilde{\chi}^{0}_{1} \tilde{\chi}^{0}_{1}.
}

The second possibility depicted in the right part of Fig.~\ref{figures/stopdecays} is reffered as ``T2bW'' and in this case both stop quarks decay via intermediary chargino:

\eq{t2bW}
{
    \tilde{t}_{1} \bar{\tilde{t}}_{1} \to b \bar{b} \tilde{\chi}^{+}_{1} \tilde{\chi}^{-}_{1} \to b \bar{b} W^{+} W^{-} \tilde{\chi}^{0}_{1} \tilde{\chi}^{0}_{1}.
}

    \insertTwoFigures{figures/stopdecays}
                 {figures/T2tt} % Filename = label
                 {figures/T6bbWW} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 { decay diagrams ~\cite{website:SUSYdiagrams}. }

In the T2bW the chargino mass is fixed to halfway between the mass of stop and neutralino. The third decay shown in Fig.~\ref{figures/T4tbW} combines the previous two. In this case, reffered as ``T2tb'' one of the stops decay to top quark and neutralino and the second to bottom quark and chargino.

\eq{t2tb}
{
    \tilde{t}_{1} \bar{\tilde{t}}_{1} \to t b \tilde{\chi}^{0}_{1} \tilde{\chi}^{+}_{1} \to b \bar{b} W^{+} W^{-} \tilde{\chi}^{0}_{1} \tilde{\chi}^{0}_{1}.
}

    \insertFigure{figures/T4tbW} % Filename = label
                 {0.5}       % Width, in fraction of the whole page width
                 { mixed decay diagram ~\cite{website:SUSYdiagrams}. }

In T2tb the chargino and neutralino are almost mass degenerate, the chargino mass is fixed by relation $m_{\tilde{\chi}_{1}^{\pm}} = m_{\tilde{\chi}_{1}^{0}} + 5~\mathrm{GeV}$  motivated by cosmological observations. Because of this small difference between chargino and neutralino masses, the W-boson is produced ofshell and its decay producst have low transverse momenta and are probably not reconstructed. If the jets from hadronically decaying W-boson are not reconstructed, only the two b-jets are present in this signal topology, what is being one of the motivation to search for final states with less jets than the four expected.


-what they are, how they look like
-t2tt, t2bw,...

-> the motivate variables and backgrounds



\subsection{Analysis strategy}

Because of the two neutralinos, the signal processes (T2tt, T2bW and T2tb)  can have final state signature largery differing from the background processes coming from Standard Model. This knowledge of the signal and background signature is used to define the baseline search region, in which the SM background is supressed. This baseline search region is then divided to smaller signal regions with help of discriminating variables. These variables are useful to define signal regions where some of the signals are enriched or some fo the backgrounds are more reduced. The remaining backround is estimated from data-driven techniques or simulations for each signal region. In teh baseline search region there are three groups of backgrounds present. 

The leading background is ``Lost lepton'' background mainly coming mainly from $\mathrm{t\bar{t}} \to 2 \ell$ processes, where both W-bosons decay into leptons and one of the charged leptons is lost because of acceptance or other critearia. This background is reduced by applying veto on second lepton, which was misreconstructed, but even after this it remains the largest backround. The subleding background is ``One lepton'' background, which mainly composed of W+jets and $\mathrm{t\bar{t}} \to 1 \ell$ processes in which the W-boson decays leptonically. The last relevant background is denoted ``$Z \to \nu \bar{\nu}$'' and comes from processes such as $t\bar{t}Z$ and $WZ$ in which the Z-boson decays to two neutrinos and one of the W-bosons leptonically.  

The signal and estimated background yields are compared with data in the signal regions and in case that no excess from the SM is observed, the exclusion limits can be put on given signal models.

In the following two subsections \ref{sec:variables}, the variables designed for definition of baseline search region and its division to signal regions will be introduced and justified on the exaples of signal topologies.  It is also discussed why and how much the backgrounds should be suppressed with regard to the choice of the variables. In the end the final definition of the baseline and signal regions for the presented analysis is revealed.

%binned approach in variables which tend to reduce signal
%single top?

\subsection{Variables~\label{sec:variables}}

\textbf{Number of leptons~($N_{\ell}$)}

The presented search focuses on final states with one charged lepton and therefore requirement on number of leptons to be equal to one must be imposed. The lepton is either electron or muon and the events with tau leptons are rejected.

\textbf{Number of jets~($N_{J}$)}

As shown on example in blue on the left of Fig.~\ref{fig:figures/T2ttlep1}, four jets are expected in the final state. But as already discussed, because of the low mass diffference between chargino and neutralino in case of T2tb, the two jets from hadronically decaying W-boson have low \pt and thus they do not have to be reconstructed and only two jets are expected. In case of high $\Delta m$ the decay products of stops can be boosted and thus two or more jets can be merged into one, resulting to reduced number of reconstructed jets in final state. The baseline requirement is to have at least two jets, but this variable is also used for the definition of signal regions targeting different topologies.

%TODO jets PT, eta, jet wp

    \insertTwoFigures{figures/T2ttlep1}
                 {figures/T2ttlepJET} % Filename = label
                 {figures/T2ttlepMET} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 { decay diagrams ~\cite{CMS:2016vew}. }

\textbf{Number of b-jets~($N_{b}$)}

In the left diagram of Fig.~\ref{fig:figures/T2ttlep1} it can be also noticed that two of the jets in green are originating from the b-quark. For this reason number of b-tagged jets selected by medium working point of CSVv2 are one of the disriminating variables. In the signal regions where W+jets background is dominant, the tighti b-tagging working point is used to further suppress it, as teh jets are expected to be mainly composed of light flavours.

\textbf{Missing transverse energy~(MET or $E_{T}^{miss}$)}

Right diagram of Fig.~\ref{figures/T2ttlep1} shows that in the final staes of the signal processes there are two neutralinos and neutrino originating from the leptonicallyd ecaying W-boson. These particles escape detector and cause missing energy in transverse plane, reffered as ``Missing transverse energy''. This variable is very powerful in rejection of SM backgrounds bacouse they tend to have small values of MET as the sources of the MET are more limited than in case of signal. Therefore the basline selection requires MET to be larger than 250~GeV. The distribution of the MET in the baseline search region for all relevant backrounds and selected signal points is shown in the left plot of Fig.~\ref{fig:figures/METMT}. In this Figure the one lepton background is decomposed to ``1l from top'' composed of $t \bar{t} \to 1\ell$ and ``1l not from top'' populated by W+jets processes. The MET was also found to be good variable for definiton of signal regions.

Because of the two neutrinos and misreconstrcuted lepton in lost lepton background, the MET of this background can be very large, which also applies for $Z \to \nu \bar{\nu}$ background, where the source of MET are three neutrinos.

\textbf{Transverse mass of lepton-MET system~($M_{T}$)}

The MET in combination with the $M_{T}$ defined as

\eq{MT}
{
 M_{T} = \sqrt{2 p_{T}^{\ell} E_{T}^{miss} (1 - \mathrm{cos}(\phi)) } ,
}

where $p_{T}^{ell}$ is the transverse momentum of lepton and $\phi$ is the angle between momentum of lepton and MET, ensure dramatic reduction of the SM backround. The $M_{T}$ is  designed to suppress backgrounds where both lepton and MET (neutrino) come from one W-boson. In such case the $M_{T}$ has an endpoint at W-boson mass. As shown in the left diagram of Fig.~\ref{fig:figures/T2ttlep2} for the signal the leptonically decaying W-boson is not the only source of MET and therefore it has no endpoint.

    \insertTwoFigures{figures/T2ttlep2}
                 {figures/T2ttlepMT} % Filename = label
                 {figures/T2ttlepDPHI} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 { decay diagrams ~\cite{CMS:2016vew}. }

The baseline selection on  $M_{T}$ variable was chosen to be  larger than 150~GeV, which supresses hugely mainly one lepton bacgrounds. The leton and MET in both  W+jets and $t \bar{t} \to 1\ell$ originate from one W-boson and thus their $M_{T}$ should have endpoint at W-boson mass~($\sim$80~GeV). It can be seen in the right plot of Fig.~\ref{fig:figures/METMT}, that indeeed the bulk of the one lepton events have low $M_{T}$, but there are tails with high $M_{T}$. In case of $t \bar{t} \to 1\ell$ the top quark constraints the kinematics of W-boson and therefore the tail in $M_{T}$  is mainly caused by MET resolution. The situation is different for W+jets, where the kinematics permits offshel production of W-boson and consequesntly $M_{W^{*}}> 80$~GeV. For the lost lepton and $Z \to \nu \bar{\nu}$ backgrounds there is no endpoint as the MET does not originate from one W-boson.

    \insertTwoFigures{figures/METMT}
                 {figures/LogMET2j} % Filename = label
                 {figures/LogMT2j} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 { decay diagrams ~\cite{website:stopSupp}. }

\textbf{Minimal azimuthal angle between direction and  one of the two leading jets and MET~(min$\Delta \phi (j_{1,2}, E_{T}^{miss})$ )}

In the backgrounds where the neutrino is only source of the MET it is probable that the neutrino is close to the b-quark  originating from the same top decay. This mainly appears for $t\bar{t} \to 1\ell$ process as shown in the left plot of Fig.~\ref{fig:figures/DPHIMLB}. In case of the signal, as depicted in the right diagram of Fig.~\ref{fig:figures/T2ttlep2}, there are more sources of MET and therefore there is no constraint on this variable. The chosen baseline requirement on min$\Delta \phi (j_{1,2}, E_{T}^{miss})$ to be larger than 0.8 is considerably reducing the SM backgrounds but leads to the relatively small reduction of the signal.

    \insertTwoFigures{figures/DPHIMLB}
                 {figures/LogMDPhi2j} % Filename = label
                 {figures/LogMlb2j} % Filename = label
                 {0.45}       % Width, in fraction of the whole page width
                 { decay diagrams ~\cite{website:stopSupp}. }

\textbf{Invariant mass of the reconstructed lepton and the closest b-quark~($M_{\ell b}$)}

In case that lepton and b-jet come from one top as displayed in Fig.~\ref{fig:figures/T2ttlepMlb} , there is a bound on the $M_{\ell b}$ variable wich is

\eq{Mlb}
{
 M_{t} \sqrt{1 - \frac{M_{W}^{2}}{M_{t}^{2}} } \approx 153~\mathrm{GeV} ,
}

where $M_{W}$ is the mass of the top quark and $M_{W}$ the W-boson mass. This limit is true for backgrounds coming from $t\bar{t}$ decay, but also for T2tt signal. On the other hand there is no limit for W+jets backgrounds and T2bW signal. Therefore this variable is not suitable for baseline region definition, as puting a constraint on it would considerably reduce the signal but it can be used to define signal regions with enriched one kind of signal and supressed one type of the background. The distribution of  $M_{\ell b}$ for all relevant signals and different backgrounds in the baseline search region is shown in Fig.~\ref{fig:figures/DPHIMLB}, where it can be clearly noticed that low $M_{\ell b}$ part of distribution si more lost lepton and T2tt-like, while high $M_{\ell b}$ is mainly populated by W+jets and T2bW-like signal.

    \insertFigure{figures/T2ttlepMlb}
                 {0.5}       % Width, in fraction of the whole page width
                 { decay diagrams ~\cite{CMS:2016vew}. }

\textbf{Modified topness~($t_{mod}$)}

The topness is $\chi^{2}$-like type of variable developed to supress background coming from $t \bar{t} \to 2\ell$ processes, where one lepton in misreconstructed. It aim is to discriminate how well an even agrees with $t \bar{t} \to 2\ell$ hypothesis. It was discovered that removing several terms from topness variable, improves the signal disrimination in this analysis. The new variable called ``modified topness''~($t_{mod}$) is defined as


\eq{tmod}
{
 t_{mod} = \mathrm{ln(\mathrm{min}S)},~where~S(\vec{p}_{W}, p_{\nu, z} ) = \frac{(m_{W}^{2}- (p_{\nu}+p_{\ell})^2 )^2 }{a_{W}^{4}} + \frac{(m_{t}^{2}- (p_{b_{2}}+p_{W})^2 )^2 }{a_{t}^{4}},
}

with $m_{W}$ and  $m_{t}$ is the mass of W-boson and top quark, ${p}_{W}$, ${p}_{\nu}$, ${p}_{\ell}$, ${p}_{b_{2}}$ are momenta of W-boson, neutrino, lepton and b-jet. The parameters $a_{W} =5$~GeV and $a_{t}=15$~GeV are the resolution parameters. The first term in Eq.~\ref{eq:tmod} aims to reconstruct mass of the W-boson which lepton was reconstructed and the purpose of second term is reconstruct the top mass of the leg, where lepton was lost. There are more options how to chose  b-jet. Several options were studied for case of this analysis following procedure was chosen. The modified topness is computed for three jets with highest CSVv2 discriminator. Then the jet which lead to the smallest modified topness is chosen.

Different backgrounds and signal models with different $\Delta m$ populates $t_{mod}$ distribution shown in Fig.~\ref{fig:figures/Logtmod2j} diferently, therefore this variable is valuable for definition of signal regiions.

    \insertFigure{figures/Logtmod2j}
                 {0.5}       % Width, in fraction of the whole page width
                 { decay diagrams ~\cite{website:stopSupp}. }

\textbf{$M_{T2}^{W}$}

The purpose of $M_{T2}^{W}$ is similar as of modified topness, to reduce the lost lepton background. This variably simillarly tries to reconstruct event under $t \bar{t} \to \ell \ell$ with one lost lepton hypothesis. The $M_{T2}^{W}$ has an endpoint at top mass for $t\bar{t}$ events with lost lepton. It would be possible to use this variable for baseline selection and requiring high values of $M_{T2}^{W}$, but it was found out that signals with low $\Delta m$ also lead to small $M_{T2}^{W}$. In the past versions of analysis the $M_{T2}^{W}$ was used for definition of signal regions. The $M_{T2}^{W}$ has very similar behavior as $t_{mod}$ and with more statistics collected it was found out that $t_{mod}$ is more discrimininat in full analysis phase-space than $M_{T2}^{W}$ and therefore in current analysis $M_{T2}^{W}$ is not used anymore.

\textbf{Number of W-tags~($N_{J}$)}

In case of high  $\Delta m$ signals the top quarks are expected to be significantly boosted. As in the SM the top quark is the heaviest particle, similar source of boost of top quarks is not present within SM and therefore tagging of boosted objects could help the signal discrimination. As show in Fig.~\ref{fig:figures/boostedTopologies} when the momentum of hadronic top is low, three resolved ak4 jets are observed. With growing boost of the top guark, the jets originating from W-boson or all three jets of the top quark can be merged into one fat jet. The merged jets can be taged by special W- or top-tagging techniques.

    \insertFigure{figures/boostedTopologies}
                 {0.99}       % Width, in fraction of the whole page width
                 { W, top tag }


Part of my contribution to the presented stop searches was study of W-tagging techniques and evaluation of its benefits for the stop search. The study was performed based on results of single lepton stop analysis~\cite{Sirunyan:2016jpr} which is using data collected at center-of-mass energy of 13~TeV in 2015 which correspond to integrated luminosity of 2.3~fb$^-1$. This analysis defines four kinds of signal regions targeting signals with different kinematics. In case of this study we focused only on region groups with high $\Delta m $ reffered as ``High $\Delta m$'' and ``Boosted High $\Delta m$'' defined in Table~\ref{tab:SRnoW}. This study redifines the signal regions with use of number of W-tagged jets~($N_{W}$) instead of \MET, but keeps the number of the signal regions the same. The proposed signal regions are shown in Table~\ref{tab:SRW}.

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
Name            & $N_{J}$  & $M_{T2}^{W}$~[GeV] & $E_{T}^{miss}$~[GeV]  \\
\hline
\hline
                & $\geq$4  & >200                & 250<$E_{T}^{miss}$<350   \\
High $\Delta m$ & $\geq$4  & >200                & 350<$E_{T}^{miss}$<450   \\
                & $\geq$4  & >200                & $E_{T}^{miss}$>450   \\
\hline
Boosted High $\Delta m$ & 3  & >200                & 250<$E_{T}^{miss}$<350   \\
                        & 3  & >200                & $E_{T}^{miss}$>350   \\
\hline
\end{tabular}
\caption[Table caption text]{2015 default sr definitions. }
\label{tab:SRnoW}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
Name            & $N_{J}$  & $M_{T2}^{W}$~[GeV]            & $E_{T}^{miss}$~[GeV]    & $N_{W}$ \\
\hline
\hline
                          & $\geq$4  & >200                & 250<$E_{T}^{miss}$<350   & --   \\
High $\Delta m$ W-tagging & $\geq$4  & >200                & $E_{T}^{miss}$>350       & 0    \\
                          & $\geq$4  & >200                & $E_{T}^{miss}$>350       & 1    \\
\hline
Boosted High $\Delta m$ W-tagging & 3  & >200              & $E_{T}^{miss}$>250 & 0  \\
                                  & 3  & >200              & $E_{T}^{miss}$>250 & 1  \\
\hline
\end{tabular}
\caption[Table caption text]{2015 default sr definitions. }
\label{tab:SRW}
\end{center}
\end{table}


The standard jets used in analysis are clusterized by ak4 algorithm with cone size of 0.4. The boosted W-jets are expected to be ``fat'' and therefore they need to be reclustered with different cone size. In the study two possibilities were exploited, ak8 jets with cone size of 0.8 and ak10 jets with cone size of 1.0. The merged W-jet should have large transverse momentum and mass around the mass of W-boson. To discriminate if the jet is merged jet originating from a W-boson, a requirement on its mass can be posed. The raw mass  of the jet is contaminated by the initial state radiation, underlying events and pile-up and tehrefore it must be cleand from these contributions. Several ``grooming techniques'' of the jet mass were developed by CMS, but in this study only pruned mass is used, as it was recomended technique for the merged W-jets. The pruning procedure~\cite{Ellis:2009su} rejects large angle and soft constituents during reclustering iterations. Another variable used in W-tagging is called N-subjettiness~($\tau_{N}$) which aim is to disriminate how the jet is consistent with N-jet hypothesis. The N-subjettiness ratio $\tau_{21} = \tau_{2}/\tau{1}$ has high disriminating power for merged W-jets and therefore in this study the requirement on jet $\tau_{21}$ is used to tag merged W-jets. Taking into acount the discriminating variables, two definitions of W-tagged jets reffered as ``ak8-W'' and ``ak10-W'' defined in Table~\ref{tab:Wtags} are established.



\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
Name            & Clustering algorithm &      pruned mass $m_{W,p}$ [GeV]  &        $\tau_{21}$  & \pt [GeV]  \\
\hline
\hline
ak8-W  &        ak8                     &   60<$m_{W,p}$<100               & <0.5   & >200  \\
\hline
ak10-W  &        ak10                     &   60<$m_{W,p}$<100               & <0.5   & >200  \\
\hline
\end{tabular}
\caption[Table caption text]{ W-tag definition. }
\label{tab:Wtags}
\end{center}
\end{table}

To evaluate the benefits of the W-tagging  the expected significance in the default signal regions in Table.~\ref{tab:SRnoW} was compared to expected significance in proposedi W-tagging signal regions in Table.~\ref{tab:SRnoW}. For this comparison all relevant backgrounds and three different T2tt signal points with different stop and neutralino mass $(m_{\tilde{t}_{1}}, m_{\tilde{\chi}}^{0}_{1})$ were used. Thsese signal point are (900,1), (800,300) and (650,450). In this study the significances for two different luminosity options of 2.3~fb$^{-1}$ and 10~fb$^{-1}$, two different options of W-tagging defined in Table~\ref{tab:Wtags} and different combinations of default and W-tagged signal regions were computed. The best performing combination of signal regions was found to be combination of ``High $\Delta m$ W-tagging'' with ``High $\Delta m$'' regions as shown in Table~\ref{tab:taggingResults}. In this table the significances of the best performing combination of signal regions for both ak8-W and ak10-W is shown together with significances of default signal regions for three signal points and integrated luminosity of 2.3~$fb^{-1}$. It can be noticed, that using ak10 jets leads to larger significance than ak8 jets. Although there is an increase in the significance up to around 20~\% in some cases, the increase is not that large to support usage of complicated and time consuming W-taggers which have gain only for high $\Delta m$ signals. Also in this study no systematic uncertainties were evaluated. But when studying the significances for different luminosities it was found that with growing luminosity the gain in significance when using W-tagging is inreasing and therefore the W-tagging is interesting option for analyses with larger integrated luminosity. 

%Table results
\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
Signal point             & --      & ak8-W & ak10-W \\
\hline
                       & High $\Delta m$ +           &  High $\Delta m$ W-tagging +  &   High $\Delta m$ W-tagging +  \\
                       &  Boosted High $\Delta m$    & Boosted High $\Delta m$       &   Boosted High $\Delta m$  \\
\hline
\hline
(900,1) &     2.68 & 2.63 & 3.43  \\
\hline
(800,300) &   3.58 & 3.76 & 4.61  \\
\hline
(650,450) &   0.38 & 0.39 & 0.44  \\
\hline
\end{tabular}
\caption[Table caption text]{tagging results for 2.3fb. }
\label{tab:taggingResults}
\end{center}
\end{table}


%-expected significance, reject backfround hypothesis
%TODO do not forget this mainstram analysis stuff and dedicated compressed T2tt


--------------------------

-put picture of some of my presentetions with rounds (midterm probably)i
leptonic diagram~\cite{CMS:2016vew}
-variables
	MET significance?!
	MT -formula; suppress largely tt1l background; and also single top and W+jets; kinematic endpoint at W mass
	MT2W - formula; explanation; supress lost lepton (already suppressed by requiring no additional lepton, but not enough); tries to reconstruct the event under tt2l and one undetected lepton assumption; for signal large delta M leads to alrge MT2W, while small delta M has lage MT2W; endpoint at top mass
	tmod - formula; chi2 like variable how well the event agrees with tt2l hypothesis, similar behavior to Mt2W; removing some of the terms from oifficial topness helps the discrimination; works better at low jet multiplicities than MT2W
	min dphi (jet, MET) - formula
        Njets
	Mlb

\subsection{Backgrounds}
-backgrounds 
	what type of
-how they look like, how they can be distingusehed from signal
	tt2l - lost lepton does not obey MT<MW
	W+jets - offshel Ws - no endpoint at W mass
	Znunu no bound Mt<MW

\subsection{Triggers, data and simulated samples}

	single lepton and MET triggers
	double lepton - to check kinematics of lost lepton
	single photon - to check MET resolution

-MC samples
	fastsim

\subsection{Objects and event selection}
	vertex selection 
	lepton selection - high pt isolated lepton, no veto lepton to reduce tt2l
	isolated track veto - tracker isolation to avoid taus
	hadronic tau veto (2015) - additional to the isolation, or selects additional taus
	jets - ak4 (pt>30, eta<2.4), medium working point for btag(CsVv2) (2015)
	MET - sum of PF candidates, type-1 corrected - jet energy correction applied to the jets in MET calculation, MET filters


\section{Search strategy - latest analysis}
- preselection (baseline selection), nr of jets, min dphi, MT, MET
then binning in 4 search variables
	N jets - we expect 4, but jet can be lost if neutralino and chargino are mass degenerated (soft jet), or if jets are merged
        	(ICHEP 2,3 and 4+ jets, now 2 and three jets bins merged)
	tMod - during ichep only at some search regions otherwise MT2W, now with more stats, this variable can be used everywhere (tmod<0 compressed, tmod>10 large dm, in between bulk)
	Mlb >175(T2bW or W+jets like), Mlb<175 (T2tt) invariant mass of closest b jet to lepton and lepton
		fir regions with high mlb and tmod large contribution of W+jets -> modification of b-tagging - 1 and more tight b-jets
	MET
	-> 27 search regions (exclusive)

+ compressed mW<dm<mt
	same preselection plus
	ISR -> 5th jet, leading jet not b-tagged
	soft lepton - pT<150GeV
	boosted top quarks dphi(lep,MET)<2
	min dphi(jet,MET)>0.5
        -> 4 MET bins
in totality 31 signal regions

\subsection{Baseline selection}
	exactly one good lepton
	MT, MET
	MT2W (2015) below and above 200GeV -> in compressed spectra the MT2W is small (similar to background), in large mass spliting it can strongly suppress tt2l
	3 or 4 jets - boosted topologies (2015)
        compressed spectra (2015) tmod instead of MT2W + two jets - jets are soft, the only visible ones are from b-tag hadronization

\subsection{Signal regions}
	- first vertex in event pass the good quality criteria
	- pass one lepton selection
	- reject additional (veto) leptons
	- at least two jets
	-at leats one b-tag
	-MT>150
	-dphi>0.8
	+ compressed, boosted high delta M, low delta M, High delta M regions (in 2015)

-\subsection{Control regions}



-binning in
	MET
	MT2W (2015)
	

\subsection{Undefined}
-SF, rewighting

\subsection{compressed spectra}
	ISR jets
	recoil, enhance MET

\subsection{Background estimation}

-data driven + simulation
-general idea
-MET extrapolation?
-transfer factors
-scale factors - take into account differences in lepton, b-tagging etc efficiency
-composition of backgrouns - percentage

\subsubsection{Z to nunu}

-ttZ, WZ, ZZ
-2015 dataset taken from simulation -> small stats
-large in high MET and MT2W regions

-2017
-ZZ still taken from simulation
-3l scale factor -> normalization

\subsection{Single lepton}

-sensitive to MET and MT
-W+jets, tt1l
- tt1l -> constrained kinematics of W due to top, so MT tail is just due to MET resolution
-W+jets, no kinematics constraint, MT tail due to of shell W production (W width) 
-W+jets, zero b-tag control region
-tt1l -> negligible, estimation from simulation

-1 lep neutrino from W decay

ESTIMATIN:
-data driven, similar as for the lost lepton
-CR contamination N CR,data,Wjets,0btag = N CR,data,0btag - N CR,MC,ninWjets,0btag
-MET and NJET extrapolation (2015)
-W+b modelling systematics

\subsection{Lost lepton}

-dominant background after MET and MT selections
-tt2l wit both Ws decaying leptonically and one lepton lost
-largest contribution is the tt2l, then single top and then ttV and diboson processes.
-dilepton control region
-misreconstruction of lepton - 1 lepton and large MET
-two enutrinos lare MT and MT2W

ESTIMATON:
- N data,SR (ll) / N data,CR (ll) = N MC,SR (ll) / N MC,CR(ll) -> get N data,SR
-MET and Njet extrapolation (2015) -> additional transfer factor
-good modeling of njet and MET needed -> mismodelling in ssimu leads to mismodelling in TF -> special emu CR -> additional SF due to mismodelling
-gamma plus jets -> MET resolution > bin migrations - gamma pt spectrum reveighted to match neutrino pt spectrum, from reweighted events METmodified = reconstructed-MET + pTgamma


-systematics

\subsection{Results and interpretation}

\section{Differences in previous analyses}

\section{Selected topics}

\subsection{W-tagging}

\textbf{Motivation}

	high delta M regim - boost -> jets merge

\textbf{Techniques}
	larger radius jets
	tau ratios - N subjetiness
	different masses-> grooming techniques
	
\textbf{Results}
	end of 2015 - slide 8,9 - results on different ak8 W-tagging categories (18/11); lumi=2 1/fb
	mid of 2016 -update of previous study - lumi=2.26 fb; ak8+ak10 tagging; tables slide 7, 11 -> mo improvement with ak8, but slight improvement with ak10 


\textbf{Perspectives}
	-results from Sicheng with top tagging
	-resolved top tagger - 3ak4 jets
	-second presentation (31/01 same as 12 feb?), slide 6 - interesting plot, slide 10,11 significance table
        -merged top tagger - boosted objects
		slide 4, 5, 6

\subsection{Depndence of discriminating variables on pileup}
-not much to say
	
