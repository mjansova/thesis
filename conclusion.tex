\chapternonum{Conclusion}

%TODO past/present

This thesis is divided into two parts, first part is dedicated to the CMS detector and especially the CMS silicon strip tracker. The studies and measurements in Chapter~\ref{sec:HIPch} were motivated by the observed inefficiencies in the tracking during the 2015 and 2016. The first analysis of this chapter performs study of the HIP events as a possible explanation of these inefficiencies. Shortly, it was realized that the HIP effect alone is not responsible for the inefficiencies in tracking, but not optimal settings of APVs was found the main cause of them.  The APV settings were quickly changed and second data were taken in order to perform analysis of the HIP events which does not suffer from the inefficiencies introduced by the APV settings. This fact and also the conditions of the data-taking has provided a possibility to perform a first HIP probability measurement at CMS. The HIP probability per pileup has been computed computed for each layer/wheel/ring of the silicon strip tracker and it has been found to be of the order of~$10^{-6}-10^{-5}$ depending on the tracker layer/wheel/ring. This analysis also focuses on the fake clusters induced by the HIP events. 

In Chapter~\ref{ch:simu} the simulation of clusters in the silicon strip tracker is discussed. The dependency of the cluster charge, seed charge and width on the parameters used in the simulation has been shown. It has been identified that the outdated cross talk parameters lead to the discrepancies of of the cluster seed charge and width description between data and simulation. This observation motivated the measurement of the cross talk parameters from the 2018 CRUZET VR data. Unfortunately, due to trigger condition, only cross talk in barrel could be measured and a new cross talk for the disks and endcaps had to be evaluated with help of both data and simulation. The new cross talk parameters improved largely the description of data by simulation in the cluster seed charge and cluster width and therefore they have been included into the official release of the CMS software.

The Chapter~\ref{sec:stopch} describes performed Run~2 searches for the top squark pair production in the single lepton final state and especially focuses on the analysis of the full 2016 dataset corresponding to the integrated luminosity of 35.9~fb$^{-1}$. This chapter discusses the whole analysis chain and highlights my contributions to this analysis. No excess from the standard model has been observed in any of the studied stop decay modes which are $\tilde{t}_{1} \to t  \tilde{\chi}^{0}_{1} $, $\tilde{t}_{1} \to b  \tilde{\chi}^{\pm}_{1}$, and $ \tilde{t}_{1} \to t  \tilde{\chi}^{0}_{1}/\tilde{t}_{1} \to b  \tilde{\chi}^{\pm}_{1} $ and therefore the exclusion limits has been derived in terms of simplified model spectra in the plane of the stop vs. LSP masses. The strongest limit on the stop masses has been obtained for the decay mode where both stops decay to b-quark and neutralino $\tilde{t}_{1} \to t  \tilde{\chi}^{0}_{1}$. In this case the full 2016 analysis is excluding the stop masses up to 1120~GeV for a massless LSP. This result is reaching the naturalness limit on the stop mass which was identified to be around 1~TeV. At the end of this chapter the naturalness bound is revisited and the constraints on the masses of the SUSY particles from the observed cold dark matter density are also discussed. The final thoughts are about the possibility of the SUSY theories beyond the MSSM.

%GENERiAL
comments from E in literature_detector directory
comments from C in papaer
give the most final result, quantifi improvement, change etc.
do not refer to chapters probabaly
motivation for studies
type of studies
results achieved
perspectives
the big picture
%----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

%HIP
results
	-first studied the hi effect as a possible explanation of the inefficiencies
	-first study with the CMS data, studied the evolution of baseline and raw digis standard deviation and with their help designed the selection of the HIP, it was found out that the HIP leads to the low baseline and low rms raw what was also observed in the 2nd study provided opportunity to study data not affecte dby the ineffeicincies
	-the HIP effect affects the cluster charge and multiplicity and in the first study a decrease in the cluster multiplicity form average, i.e. dead time, is observed for aroun 250 ns.
	-Due to the data-taking properties the deadtime cannot be studied in data after vfp fix, but with these data we have shown that there is an increased multiplicity of fake clusters after a HIP event. But in average this multiplicity is of the same order of magnitude as the cluster multiplicity of fake clusters when no HIP is present. We have also estimated a lower bound on the probability that a fake cluster from a HIP event is reconstructed into track to be 0.002\%. We observed that these fake clusters originate from the baseline distortiond induced by the HIP event. 
	-We have computed that the hip probability per pileup for each layer/wheel/ring of the silicon strip tracker and it has been found to be of the order of~$10^{-4}-10^{-3}$\% depending on the tracker layer/wheel/ring. This means that in case of dead time for 250ns and bunch spacing of 25ns the PU of order of $10^4-10^5$  would cause that the APV chip is never fully efficient (ask prob of 10 events before have a HIP) and we are far from that now.
	-HLLHC expected pu 140-200
 
is there something to be improved
	-different design of the APV chip. The common powering of inverters causes the drop o baseline but o the other hand it stabilizes the baseline. The resistance of the inverter resistor was changed in order to improve the sensitivity to the HIP event, but it enhances the instabilities of baseline, the basline distrotion, leading to a possible enhancement of the fake cluster reconstruction.

does it need to be monitored
	-the HIP probability is now low and tehrefore does not cause a large problems. But once the PU is increasing it can become dangerous, but as I mentioned the PU would have to be of the order of... which is far from teh expected PU at LHC.
 
how to improve ?
	-increase of lumi, increase of PU > for HL-LHC there is a development of new chips and therefore in their design we need to pay attention to the HIP effect (does somebody already thinking about that)

could we prevent by changing baseline ref value ?
	-the HIP was tried to be mitigated by maximizing CMN. But it was found out taht this maximization elads ony to the appearance of the so-called "anomalous cluster" (more details in HitEffLoss page). This check was though done before the APV change and should be redone. But the problem is that due to the HIP tehre are also fragments causing clusters plus fakes from distrotions which would not be normally reconstructed as they are below zero. So would it be the right thing to do?  %slide 27: https://indico.cern.ch/event/470862/contributions/1146979/attachments/1281240/1903454/common_mode_maximization.pdf

will we suffer of this at HL-LHC ?
	-we will ahve a HIP effect but it consequences, the induced dead time and probability will depend on the design of modules.

something about the APV conditions?
	-Preamp Feedback Voltage Bias (VFP) Change
	-not much to say...

which kind of data would be perfect?
	-theoretically the best option would be data without trigger rules. Then we measured probabilities but we miss deadtime. so we would need subdeetctors in to have tracking. And to link the track to the module with HIP. To measure dead-time we would need trains and to track a given module and asseswhn clusters start to be seen in that module with the help of tracking again. The analyiss would need to be more complex. (Think about that a bit more). Then there is still ambiguity in HIP selection - we would need to require HIP which is alreadys een in the first event in the train and then we would need to trigger all events in a time window (dead time estimated to 250ns, so at least this window)

the common biasing scheme of inverters -> stabilize baseline but xtalk effect -> could reduce the HIP problem - check 
%----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


%SIMU
results
	- After identifying that the cross talk causes a large discrepancies in description of cluster shape, we have decided to arrange a data-taking and remeasure it
	- measurement done (differences between barrel and endcaps!) \& cross talk was found to decrease compared to the values originally int he MC
	- example of TOB2 measurement before and after
	- found evolution of xtalk as a function of time
 	- what remains unchanged - many parameters were found otdated but not updated week dependence -> should be some update later, but just for consistency
	-cross talk: Said somewhere that it was done last time in 2010 ?

does it need to be remeasured
	- As shown the cross-talk evolves with fluence and tehrefore it must be remeasured from time to time.  Interesting feature is that the evolution is opposite than expected and therefore it would be interesting to monitor the cross talk in the vision of understanding the feature.

do we need a different data
	-the cruzet cosmics is good, but ideally we would need also some data from endcaps and this is difficult with cosmics as we would need quite a lot of time. The ideal case would be zero tesla collision data in the virgin raw, but this is scifi. These data would help to collect large stats everywhere, plus we would not have problems with timing.

how can we improve the emasurement and the physics
	-we could potentionally measure if there is left-right assymetry of cross talk (in past and this work observed average cluster (seed) charge dependency on the cluster position burt between 3); if the cross talk is dependent o the cluster position and track position within a sensor. But the description now is in general good and as mentioned there is only a small dependency of the tracking on the cross talk. In general only the physics analyses which are using tracking i.e. searches fro the appearing/disappearing tracks; or b-tagging discriminators are influenced.
	-also we should update the cross talk in the peak data and check if the evolution is the same as in deco, the crosss talk decreases, this could give us a hint what is going on

can we introduce some new things in simu
	-for now we have achieved improvement and there are no things to be introduced into simu. After updating the conditions everything seems to be better described except the fraction of saturated clusters. This need to be resolved and changes in simulation might be done. On the other hand there are parts of simulation, where the effect is really small, e.g. diffucsion and if we would target the simplification of the code i order to reduce the simulation time, certainly few things could be simplified
 
are there some problematic things in simualtion
 -in my opinion there is one large problem in simulation taht the parameters are not updated frequently. For some parameters it is not a problem, but for some it is crucial. For example the timing curve changed with the change of APV parameter and was not updated. The pulse shape largely influences teh clsuter properties and can pose really problems
	- mainly the OOT will not be corectly described, firstly of incorrect pulse shape, but also because of the dependence of the cross talk on the particle arrival time. This could be considered for implementation in the smulation.
	- then the puls shape is difefrent for the main strip and neighbor, what will cause also incorrect description of oot as we fixed it now for intime

do we need to change something more frequently or completely because the sensor changes with radiation
	- as shown except of cross talk also the noise and database conditions change fast with the aging of sensors.


pulse shape problematics -> the OOT is not well described
xtalk independent of time in simu
	-already talked about


measure it at HLLHC?
	-for sure it needs to be determined what is teh cross talk and what it evolution will be (and if we are able to do so, measured from time to time) We need to make sure that the clusters do nto fail the binary criterium because they are too wide, because of too large cross talk. 
	-soem sensors are going to be DC coupled, things will be different with xtalk
	-ensure large interstrip resistance (think about xtalk during design) 

what are the limitations ?
why outdated ? talk about irradation
	-fluence causes the aging of modules (defects, surface damage)

Do we know why it was modified?
	- not completely uderstood why xtalk is evolving in this way, but the evolution was expected due to surface damages on the sio-si interface

How to understand the change of cross talk, which goes in opproite direction, can we disentangle it by more frequent measurements?
	- it might be the cose but it does not have to

Radiation Damage (https://indico.cern.ch/event/577879/contributions/2740332/attachments/1572803/2483960/CMS-OT_aldi.pdf) - slide 23 reference

Bulk damage
	Primary lattice defects (I and V) form higher order defects (V2, VO,...) or even defect clusters, with energy levels in the band gap of Si
	Depending on energy level and cross section they contribute to leakage current, effective doping concentration, trapping

Surface damage
	-Ionizing radiation generates e/h pairs also in SiO2 
	e much higher mobility than h -> positive charge up of oxide
	Additional, interface traps with dynamic characteristics
	Theses lead to increased surface currents, altered electric field in surface region, accumulation of electrons at surface
%----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


%SUSY
motivation, conclusion
	-the standard model of the particle physics was over years found to be excelently describing the nature, nut there are several shortcomings
	-the most popular extension of sm du to its ability to addrss many shortcommings
	- limits already at runI but runII due to cnage in energy and larger integrated luminosity enabled to probe stop masses far beyond the runI possibilities
what was done and my contribution
	-search for the supersymmetric partner of teh stop
	-three posible decay channels, top neutralino, bottom chargino and mix of them
	-search in one lepton final state + jets + met
	-three analyses - my largest contribution to the full 2016
	-the largest contribution to the full 2016 is estimation of the z to nunu background

perspectives at HLLHC
	-the relatively light stops already excluded
	-the naturalness can be achieved with heavier ones therefore we must keep searching
	-at the HL-LHC integrated lumi of 3000 fb-1 by CMS to be 2TeV
	-further probing could be achieved by increase of the center of mass energy
	-beyond this the more spohisticated analysis techniqus can eb designed to further probe the stop masses - like W or top tagging, new disriminating variables or machine learning teqniques

perspectives:	What about the search at low mass ?
perspectives:	How to improve ?
perspectives:	How to interpret in a realistic model ? Do we have other strong constraints from other measurements/ serches ? ...
%----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
