\clearpage

\setcounter{secnumdepth}{4}
\chapterwithnum{The CMS experiment at the LHC}
\setcounter{secnumdepth}{5}

There are several options how to study matter, for example it can be studied via cosmic rays and neutrinos, gravitational lensing or at collider experiments. In Section~\ref{sec:LHC} the largest existing collider, the LHC, and its experiments are introduced. In Section~\ref{sec:CMS} the CMS detector, in which context this thesis is performed, is described. Then in Section~\ref{sec:objects}, object reconstruction techniques of the CMS collaboration applied on the CMS data are introduced. A special interest is put on the topics whose deeper understanding is required for the following chapters of this thesis.

\section{The Large Hadron Collider~\label{sec:LHC}}

The Large Hadron Collider~(LHC)~\cite{CERN-Brochure-2017-002-Eng, Evans:2008zzb} is a particle accelerator with a circumference of 27~km, which is a part of the CERN accelerator complex~\cite{Bruning:2004ej} located near Geneva, Switzerland. The LHC project was approved in 1994 and designed to provide mainly collisions of protons. Part of the LHC operation time is also dedicated to collisions of heavy nuclei, but in this thesis only the proton collisions are described.

A schematic view of the CERN accelerator complex with its main experiments is presented in Fig.~\ref{fig:figures/CCC-v2016}~\cite{Mobs:2225847}. At the beginning of the acceleration process the protons are obtained by stripping electrons from the hydrogen atoms. Protons are then accelerated through a chain of accelerators: Linac2, Booster, Proton Synchrotron~(PS) and Super Proton Synchrotron~(SPS). The proton beams accelerated to 450~GeV are injected from the SPS into the LHC~(both clockwise and anti-clockwise). In the LHC, the beams are further shaped and accelerated with eight radio-frequency~(RF) cavities per beam, currently to the beam energy of 6.5~TeV. The LHC is equipped with 9593 magnets, mainly dipoles and quadrupoles, to bend and focus the beams. There is an ultrahigh vacuum of order of $10^{-10}-10^{-11}$~mbar in the LHC tube to avoid collisions of particles with gas, the vacuum of around $10^{-6}$~mbar is being also used for isolation  of cryomagnets and helium distribution line.

    \insertFigure{figures/CCC-v2016} % Filename = label
                 {0.99}       % Width, in fraction of the whole page width
                 { The CERN accelerator complex~\cite{Mobs:2225847}. }

The proton beams are not homogeneous but composed of trains of bunches, each bunch containing around 100 billions of protons. Bunches within a given train are spaced by 25~ns. Time gaps between two different trains are longer, their duration depends on the beam structure and it starts from few multiples of 25~ns. The LHC uses several beam structures, which are specified by the filling scheme. An example of a beam structure is shown in Fig.~\ref{fig:figures/beamStructure}. The proton beams are accelerated in separate pipes and then collided against each other at four interaction points~(IP). For the moment, the LHC operation is divided into two eras, Run~1 and Run~2. The Run~1 started in 2008 and ended in 2013. During this era the center-of-mass energy of the collisions was first 7~TeV, then increased to 8~TeV in 2012, and the beam structure allowed collisions every 50~ns. The Run~2 started in 2015 and is still ongoing. In the Run~2 the collision center-of-mass energy increased to 13~TeV and the time between collisions was reduced to 25~ns.

    \insertFigure{figures/beamStructure} % Filename = label
                 {0.7}       % Width, in fraction of the whole page width
                 { (top) An example of beam structure. The beam pipes are shown in red and violet and the beams are drawn in green. (bottom) An example showing the structure of two trains. }

The bunches of protons collide at four IPs, at which four main experiments were installed. The two general-purpose detectors, which were designed to cover a wide range of physics, are ATLAS (standing for ``A Toroidal  LHC ApparatuS'')~\cite{Aad:2008zzm} and CMS (standing for ``Compact Muon Solenoid'')~\cite{Chatrchyan:2008aa}. The other two main experiments are ALICE (standing for ``A Large Ion Collider Experiment'')~\cite{Aamodt:2008zz}, mainly focusing on the analysis of heavy-ion collisions and studies of ``quark-gluon plasma'', which existed at the early Universe and the LHCb (standing for ``Large Hadron Collider beauty'')~\cite{Alves:2008zz} specialized in the physics of the b-quark and heavy flavor quarks in general. There are also three smaller experiments along the LHC, one of them is TOTEM~\cite{Anelli:2008zza} which is close to CMS and its principal goal is to measure the total cross section of protons at LHC. LHCf~\cite{Adriani:2008zz}, which is located near to the ATLAS experiment, studies particles moving very close to the proton beams. Finally MoEDAL~\cite{Acharya:2014nyr}, which is close to LHCb, focuses on the search of hypothetical particles, e.g. magnetic monopoles.

One of the main motivations for the LHC and its experiments was the search for the Higgs boson, which was discovered in 2012. A second important topic of research is the search for new particles and more generally for evidence of physics beyond the Standard Model, motivated mainly by cosmological observations, naturalness of the Higgs mass and the desire for unification of known interactions.

\newpage

%TODO here

\section{The Compact Muon Solenoid detector~\label{sec:CMS}}

%The CMS (``Compact Muon Solenoid'') detector~\cite{Chatrchyan:2008aa, CMSproposal} is a multipurpose detector of overall length of 22~m, a diameter of 15~m and a weight of 14~t, located at the IP~5. The designed properties of the CMS  detector were to have high efficiency of muon identification and reconstruction. It was also required have precise momentum resolution in large range of momenta, dimuon mass resolution of order of 1\% at 100 GeV, good charged-particle momentum measurement and resolution~(around 1\%-2\% for 10~GeV muons in majority of CMS coverage) as well as high efficiency in reconstruction of charged-particle tracks. Furthermore it was designed to have precise measurement electromagnetic energy, leading to resolution of diphoton and dielectron mass of around 1\% at 100~GeV. Good missing transverse energy~(MET) and dijet mass resolution was required as well. One of the important requirements was also high efficiency in offline tagging of tau particles and jets originating from b-quarks. These conditions have to be fulfilled in the LHC environment, with a bunch crossing~(BX) frequency of 25~ns, where every bunch crossing leads to tens of inelastic interactions on top of the interaction of the interest, referred as ``pileup''~(PU), resulting in thousands of charged particles in the CMS detector every 25~ns. Because of this large radiation, the detectors and front-end electronics have to be radiation-hard.

The CMS (``Compact Muon Solenoid'') detector~\cite{Chatrchyan:2008aa} is a multipurpose detector of an overall length of 22~m, a diameter of 15~m and a weight of 14~t, located at the IP~5. The designed properties~\cite{CMSproposal} of the CMS  detector were to have high efficiency of muon identification and reconstruction, leading to a requirement on  a dimuon mass resolution of the order of 1\% at 100 GeV. A high quality tracking providing precise charged-particle momentum measurement and resolution around 1\%-2\% for 10~GeV muons in the majority of the CMS coverage. Furthermore it was designed to have best possible measurement the electromagnetic energy, leading to a resolution of the diphoton and dielectron masses of around 1\% at 100~GeV. These conditions have to be fulfilled in the LHC environment, with a bunch crossing~(BX) every 25~ns, where every bunch crossing leads to tens of inelastic interactions on top of the interaction of the interest, referred as ``pileup''~(PU), resulting in thousands of charged particles in the CMS detector every 25~ns. Because of this large radiation, the detectors and front-end electronics have to be radiation-hard.

To achieve the given requirements, CMS was built in layers around a large solenoidal magnet, with endcaps at each side. The CMS magnet is a superconducting solenoid providing a magnetic field of 3.8~T. The magnet is surrounded from outside by the steel yoke which returns the magnetic flux of the solenoid~\cite{tdrMagnet}. The radius of the magnet has to be kept relatively small and therefore the available space between the magnet and interaction point is limited.

Inside the magnet from the interaction point outwards, there is a pixel and silicon strip tracker, followed by the electromagnetic and hadron calorimeter. Outside of the magnet there is the outer hadron calorimeter and the steel return yoke with embedded muon chambers. The CMS detector layout is shown in Fig.~\ref{fig:figures/cmsdetector}~\cite{website:CMSdet}. In the following sections, first the coordinate system of the CMS is described. Then the CMS subdetectors are introduced, starting from the innermost one. In the end, basic information on trigger, luminosity and pileup is given.
%-coverage up to |eta|<5


    \insertFigure{figures/cmsdetector} % Filename = label
                 {0.99}       % Width, in fraction of the whole page width
                 { A schematic layout of the CMS detector~\cite{website:CMSdet}. }

\subsection{Coordinate system and conventions}


The coordinate system used by CMS~\cite{Chatrchyan:2008zzk} is sketched in Fig.~\ref{fig:figures/coordinates}~\cite{Pantaleo:2293435}. In the CMS conventions, the cartesian coordinate system has is centered at the IP, with the x-axis pointing into the center of the LHC, the y-axis going upwards and the z-axis going anti-clockwise along the beam direction. The azimuthal angle $\Phi$ is defined in the x-y plane and is measured from the x-axis. The polar angle $\theta$ is measured from the z-axis and is defined in the y-z plane. Finally the $r$ is a radial coordinate in the x-y plane. In this convention the pseudorapidity $\eta$ is defined as

\eq{pseudorapidity}
{
    \eta =  -\ln \left[ \tan \left( \frac{\theta}{2} \right) \right].
}

The angular distance between two points can be measured with the help of $\Delta R$ defined as

\eq{deltaR}
{
    \Delta R = \sqrt{ \Delta \Phi^2 + \Delta \eta^2}.
}


The transverse momentum $p_{T}$ can be computed from the x and y momentum components as

\eq{pseudorapidity}
{
    p_{T} =  \sqrt{p_{x}^2 + p_y^2 }.
}

As at the interaction point, the beams have no momentum in the x-y plane, the sum of momenta of particles originating from collision in this plane should be zero due to momentum conservation law. Therefore the imbalance of momenta in this plane, the non-zero total $p_{T}$, can be sign of particles which momentum was unmeasured, like neutrinos or hypothetical new particles. 

    \insertFigure{figures/coordinates} % Filename = label
                 {0.6}       % Width, in fraction of the whole page width
                 { The CMS coordinate system with the three axes intercepting at the interaction point, the x-axis pointing inside the LHC ring, the y-axis going upwards and the z-axis pointing anti-clockwise along the beam.~\cite{Pantaleo:2293435}. }

\subsection{The silicon tracker~\label{sec:tracker}}

The silicon tracker~\cite{CMS:1997tlf, CMS:2000eqx} is the innermost subdetector of the CMS detector. The CMS tracker is divided into two parts. The inner part consists of a pixel detector, while the outer part of a strip detector.  Its purpose is to reconstruct tracks from charged particle depositions in silicon sensors, the energy loss $E_{loss}$ lost along their path. In order to recognize from which interaction a given particle originates, the tracker is required to have a capability to reconstruct primary and secondary vertices. A track is the reconstructed path of a particle passing trough the tracker. The primary vertices are the positions where the interaction of interest or the PU interaction occurred, which are determined by the vertex fitting procedure from the tracks~\cite{Ball:2007zza}. The secondary vertices correspond to the place where a particle with a long lifetime decays to other particles. 

On the tracker level, the tracking is performed in 4 steps~\cite{website:slidesTracking, website:twikiTracking}. It starts from the hits, which are reconstructed from particle depositions in the sensors. First, the \textit{track seeding} is performed from two or three 3-D reconstructed hits with a constraint on primary vertex position. Then the algorithm proceeds with \textit{track building} which aims to connect all hits originating from one particle. During the track building the track is propagated to the neighboring layers of the tracker, testing the compatibility of the reconstructed hit with the track by a $\chi^{2}$ test. Once the full track candidate is complete, the \textit{track fitting} is performed to obtain the best parameters of the track and to recompute precise hit position using the track properties. The last step is a \textit{track quality selection} rejecting tracks not fulfilling quality requirements, which are based on the $\chi^{2}$ of the final fit, the number of layers with a hit associated to the track and the probability of the track  to originate from the primary vertex.

The default track reconstruction~\cite{Chatrchyan:2014fea} is using the software referred as the Combinatorial Track Finder~(CTF), based on the combinatorial Kalman filter~\cite{Fruhwirth:1987fm}. The tracking uses an iterative approach: in the first iteration the easiest tracks to find are reconstructed (i.e. the ones with the highest $p_{T}$), then after these tracks are complete their hits are masked in order to avoid duplicities and reduce combinatorics for further iterations of tracks finding. In total there are 12 iterations and each iteration is focused on a specific type of tracks.


Due to the presence of the magnetic field, charged particles are bent according to their momentum and charge, thus the CMS tracker is able to measure the charge sign and the momentum associated to a track. To perform so, the tracker needs to have good spatial resolution and to be extremely radiation-hard due to the large flux of incoming particles. Also the material was chosen carefully, in order to reduce multiple scattering, nuclear interactions or bremsstrahlung in the tracker material.

The flux of particles in the CMS detector decreases with the distance from the interaction point, the flux of charged particles in the barrel at radius of 4~cm is around $10^{8}~\mathrm{cm^{-2}s^{-1}}$ while at radius of 115~cm it decreases to around $3 \times10^{5}~\mathrm{cm^{-2}s^{-1}}$. Consequently, the inner part of the tracker is made of silicon pixels, which are able to measure particle paths and its properties in high particle density environment. In the outer part of the tracker, the particle density is low enough to use silicon strip sensors, which are cheaper mainly because they require less readout channels. Overall, the tracker pseudorapidity coverage is  $|\eta| < 2.5$.


\textbf{Silicon pixel tracker}

%The silicon strip tracker is 5.8~m long with a diameter of 2.5~m. 
Before 2017, the pixel barrel, referred as BPIX,  was located at radius of 4.4--10.2~cm from the IP. The pixel endcaps~(FPIX) extended on each side at 6--9~cm in the z direction. In total, there were three barrel layers and two endcaps layers on each side. In 2017, due to the high radiation exposure, the pixel tracker was replaced. The new pixel tracker has four barrel layers at radius 3-16~cm and three endcap disks at distances of 29.1--51.6~cm. The pixel detector plays crucial role in the track seeding, primary and secondary vertex reconstruction~\cite{CMS:2012sda}. 


%-new pixels - short distance from IP, high radiation -> damage -> need for replacement
%- FPIX - 3 disks on each side 29.1cm -51.6cm  (Forward pixel) ~\cite{CMS:2012sda}
%- BPIX - barrel pixel - 4 cylindrical layers radius of 3-16 cm

\textbf{Silicon strip tracker}

%15148 silicon strip modules

As the following chapters present studies of the silicon strip tracker and its simulation, it is necessary to take a deeper look into its design and properties. The silicon strip tracker is divided into four partitions. Each partition has layers of modules, which have either one side~(mono) or two sides~(stereo) of silicon sensors. In totality the strip tracker is composed of 15148 modules. The Tracker Inner Barrel~(TIB) is the innermost barrel part with two layers of stereo modules succeeded by two layers of mono modules. The Tracker Outer Barrel~(TOB) surrounds the TIB. In the innermost part of TOB, there are two layers of stereo modules, the remaining four layers are mono. On each side of the barrels, Tracker Inner Disks~(TID) and Tracker EndCaps~(TEC) are located. There are three wheels of TID with three module rings and 9 wheels of TEC with four to seven rings of modules on each side. In each wheel there is a mixture of mono and stereo modules, but each ring has either mono or stereo modules. In the barrel region, the silicon tracker is placed in radius between 20~cm up to 1.1~m from the IP. The disks start at 80~cm in the z-direction from the IP and the endcaps reach up to z=2.8~m from the IP. The overall layout of the silicon strip tracker can be seen in Fig.~\ref{fig:figures/cmsTracker}~\cite{Chatrchyan:2014fea}.

    \insertFigure{figures/cmsTracker}
                 {0.9}       
                 {A schema of the upper half of the CMS silicon strip tracker and layout of its partitions. The star represents the IP. The modules in blue are stereo, while the mono ones are shown in black~\cite{Chatrchyan:2014fea}. }

Each mono module holds 320~$\mathrm{\mu m}$ or 500~$\mathrm{\mu m}$ thick silicon sensors with either 512 or 768 silicon strips.  The strip length is between 8 and 25~cm, the distance between strips, called pitch, varies between around 80~$\mathrm{\mu m}$ and 200 ~$\mathrm{\mu m}$. The strip width to pitch ratio is 0.25. In the barrel, the strips are parallel to the z-axis, or tilted by 100~mrad with respect to the z-axis in case of the stereo sensors. In TID and TEC, the strips are aligned to be parallel to $r$. The local module coordinates have zero in the middle of the module, the z-axis goes in the direction from the back-plane to the strips, the y-axis goes along the strips, and the x-axis is perpendicular to the strips and traverses them. The local $\theta$ angle is measured from the z-axis. The local $\Phi$ is defined in the x-y plane and measured from the x-axis. The schematic view of the sensor local coordinates is shown in Fig.~\ref{fig:figures/localCoordinates}. The details about the module geometries for each layer of TIB and TOB and each ring of TID and TEC can be found in Table~\ref{tab:trackerGeometries}~\cite{website:hephyPage}.


    \insertFigure{figures/localCoordinates} % Filename = label
                 {0.6}       % Width, in fraction of the whole page width
                 { The sensor local coordinate system with the three axes intercepting in the middle of the sensor. The x-axis is perpendicular to strips, the y-axis goes along strips and the z-axis pointing from backplane to strips. }

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Layer & Type  & \#Strips & Thickness~[$\mathrm{\mu m}$] & Pitch~[$\mathrm{\mu m}$] & Geometry label  \\
\hline
\hline
TIB L1 & stereo & 768 & 320 & 80 & IB1 \\
TIB L2 & stereo & 768 & 320 & 80 & IB1 \\
TIB L3 & mono & 512 & 320 & 120 & IB2  \\
TIB L4 & mono & 512 & 320 & 120 & IB2 \\
\hline
TOB L1 & stereo & 768/512 & 500 & 122/183 & OB2 \\
TOB L2 & stereo & 768/512 & 500 & 122/183 & OB2  \\
TOB L3 & mono & 512 & 500 & 183  & OB2 \\
TOB L4 & mono & 512 & 500 & 183  & OB2 \\
TOB L5 & mono & 768 & 500 & 122  & OB1 \\
TOB L6 & mono & 768 & 500 & 122  & OB1 \\
\hline
TID R1 & stereo & 768 & 320 & 81...112  & W1a \\
TID R2 & stereo & 768 & 320 & 113...143 & W2a  \\
TID R3 & mono & 512 & 320 & 124...158  & W3a \\
\hline
TEC R1 & stereo & 768 & 320 & 81...112 & W1b  \\
TEC R2 & stereo & 768 & 320 & 113...143 & W2b   \\
TEC R3 & mono & 512 & 320 & 124...158  & W3b \\
TEC R4 & mono & 512 & 320 & 113...139  & W4 \\
TEC R5 & stereo & 768 & 500 & 126...156  & W5 \\
TEC R6 & mono & 512 & 500 & 163...205  & W6 \\
TEC R7 & mono & 512 & 500 & 140...172  & W7 \\
\hline
\end{tabular}
\caption[Table caption text]{Module type, strip multiplicity, sensor thickness and pitch and module geometry label for layers or rings of the four silicon strip tracker partitions~\cite{website:hephyPage}. }
\label{tab:trackerGeometries}
\end{center}
\end{table}


The track resolution determined in 2011 before replacing the pixel detector, is in \pt is of order of 1.5\% for non-isolated particles in range 1 < \pt < 10~GeV and $|\eta| < 1.4$ and of order of 2.8\% for particles with \pt = 100~GeV and $|\eta| < 1.4$~\cite{TRK-11-001}. The spatial resolution of the reconstructed hits for different barrel layers of the strip tracker is shown in Fig.~\ref{fig:figures/hitResolution}~\cite{website:hitEff}. The typical strip hit resolution is between 15--45~$\mathrm{\mu m}$ in the barrel region of the silicon strip tracker.


    \insertFigure{figures/hitResolution}
                 {0.6}       
                 {Measured resolution of reconstructed hit position for different layers of strip tracker and size of pitch between the strips. The red color corresponds to hits with charge deposited in one strip, green in two strips and blue in three strips~\cite{website:hitEff}. }

\subsection{The electromagnetic calorimeter}

The electromagnetic calorimeter (ECAL)~\cite{tdrECAL} is a subdetector located at outer side of the silicon tracker. In the barrel region the ECAL extends up to a radius of 1.77~m from the IP. It is an homogeneous, fast, radiation resistant calorimeter with a good energy resolution. It is composed of 75848 lead-tungstate ($\mathrm{PbWo_{4}}$) crystals and its purpose is to measure the energy of electrons and photons. The ECAL consists one barrel~(EB) covering $|\eta|<1.479$ and two endcaps~(EC) extending the coverage up to $|\eta| =3$. A preshower is placed in front of the endcaps in order to separate highly energetic single photons from the photons originating from the decay of neutral pions.

The energy resolution of ECAL was determined~\cite{Chatrchyan:2008aa} to be

\eq{ECALresol}
{
 \frac{\sigma_{E}}{E} = \frac{0.028}{\sqrt{E}} \bigoplus \frac{0.12}{E} \bigoplus 0.003 ,
}
where $E$ is the energy and $\sigma_{E}$ is the energy resolution. The first term is the stochastic part, it corresponds to e.g. fluctuations in number of particles. The second term accounts for noise and the third term covers mainly the non-uniformities, energy leakage and inter-calibration issues.


\subsection{The hadron calorimeter}

The purpose of the hadron calorimeter~(HCAL)~\cite{tdrHCAL} is to measure the energy of strongly interacting particles.  The HCAL is a sampling calorimeter composed of four parts, out of them two are located between the ECAL and the magnet, which are the HCAL Barrel~(HB) and Endcaps~(HE). Both HE and HB have a brass absorber and their active material is made of plastic scintillators. The pseudorapidity coverage of HB is $|\eta|<1.3$, and of HE $1.3<|\eta|<3$. The coverage is further extended up to $|\eta|=5.2$ by the third part called the Forward calorimeter~(HF). Installed 11.2~meters from the IP on both sides, HF is made of steel as an absorber and quartz fibers creating the active volume. The technology of HF is very radiation-hard as around one third of the particles produced in the collisions reaches HF. Because the available radial space between ECAL and the magnet ( i.e. is between r=1.77~m and r=2.95~m ) is not large enough to build calorimeter with enough stopping power, the last part of the calorimeter, the Outer calorimeter~(HO), was added after the magnet. HO is covering the region $|\eta|<1.3$ and stops particles escaping HB, for this reason it is sometimes also referred as ``tail catcher''. The magnet material is in that case used as an absorber for HO. A schematic layout of the HCAL is shown in Fig.~\ref{fig:figures/HCAL}~\cite{Chatrchyan:2008aa}.

    \insertFigure{figures/HCAL}
                 {0.7}       
                 {A schema of one quarter of the CMS HCAL with layout of HB, HE, HF and HO~\cite{Chatrchyan:2008aa}. }

The hadron energy resolution from the combination of ECAL and HCAL (barrel and endcaps)~\cite{Chatrchyan:2009ag} was measured to be


\eq{HCALresol}
{
 \frac{\sigma_{E}}{E} = \frac{0.847}{\sqrt{E}} \bigoplus 0.074 ,
}
where the meaning of the terms is similar as for the ECAL.
%- for HF 1.98/sqrt(E)+0.09 -> higher because of high energy of jets in this region but as divided by energy, it is ok

\subsection{The muon chambers}

Because many interesting physics processes have a signature with muons in the final state, good and precise measurement of muons is one of the main goals of the CMS. This comprises muon identification, momentum measurement and triggering. The good triggering and momentum measurement is achieved with the help of the high magnetic field provided by the solenoid. The measurement of muons is done in three gaseous subdetectors, the Drift Tube~(DT), Cathode Strip Chamber~(CSC) and Resistive Plate Chamber~(RPC) systems~\cite{tdrMuon}. The three muon systems combined have in total 1400 chambers, which in radial direction are placed between around 4~m up to 7.5~m from the IP. The distance in the z-direction between the inner and outer part of muon systems is about 5.5~m-11~m. The layout of the muon systems is shown in Fig.~\ref{fig:figures/muons}~\cite{Chatrchyan:2013sba}.

    \insertFigure{figures/muons}
                 {0.7}       
                 {A schematic view of one quarter of the CMS muon systems and their inner structure~\cite{Chatrchyan:2013sba}. In case of DTs MB stands for ``Muon Barrel'' and in case of CSCs ME stands for ``Muon Endcap''. The notation for RPCs is RB for barrel and RE for endcaps. }

The DTs are located in the barrel region and are partly integrated into the return yoke.  The pseudorapidity coverage is of $|\eta|<1.2$. They are composed of plane cathodes with anode wires in between the planes. The smallest unit of DTs is the drift cell of dimensions 42$\times$13~mm, in which one 50~$\mathrm{\mu m}$ thick anode wire is located. The drift time of charge carriers can be up to around 400~ns.

The CSCs are located in the endcap areas outside of the return yoke. The CSCs coverage is $0.9<|\eta|<2.4$, which is partly overlapping with the DTs. The CSCs also contain cathodes with anode wires in between, but one cathode of the pair is segmented into strips. The DTs and CSCs provide a good triggering of muons which is independent of the rest of the CMS detector.

To ensure the correct bunch crossing identification~(i.e. from which bunch crossing a given muon originates), the complementary RPCs are present in both barrel and endcap regions. RPCs are composed of parallel plates of anodes and cathodes and readout strips. The RPCs are faster than DTs and CSCs, but provide a worse position resolution. The RPCs trigger is independent of the CSCs and DTs.  

The spatial resolution per chamber differs for the three systems, for DTs it is 80-120~$\mathrm{\mu m}$, for CSCs 40-150~$\mathrm{\mu m}$, and for RPCs 0.8-1.2~$\mathrm{cm}$~\cite{Chatrchyan:2013sba}.

In the following sub-section the time measurement in DTs is introduced. The timing can be also measured with CSCs and ECAL in a very similar way, but for the purposes of the thesis, only the knowledge of the time measurement in DTs is needed.


\textbf{Muon timing measurement in DTs~\label{sec:muonTiming}}

A muon going through DTs deposits its energy by ionization of the gas. The created charge carriers drift towards the wires and are read at time $t_{read}$ as shown in the blue arrows in Fig.~\ref{fig:figures/dtTiming}~\cite{Traczyk:1365029}. If it is assumed that the muon was produced in-time with the collision~($t_{IP} = 0$) and that its speed is the speed of light, then the time ($t_{cell}$) when the muon arrives from the IP to the given drift cell can be calculated. With the knowledge of the drift velocity~$v_{drift}$, the difference between $t_{read}$, when muon charge was read at the wire, and $t_{cell}$, when muon came to the cell, can be converted into a distance between them. The distance $ v_{drift} (t_{read} - t_{cell})$,  is used to compute the hit positions where muon crossed the cells, starting from the wire as shown in blue crosses. In case that the production time was assumed correctly~(i.e. muon was created in-time with the collision), all hits should be on one line~(blue crosses). If the particle was not produced ``in-time'' with the collision time, the hits are shifted~(red crosses) and the line which connects them is not straight, but curly. The distance between the reconstructed hit and the hit on the straight line~(red line) is converted to the time~$\delta t$, which measures real arrival time of muon with respect to the expected arrival time, and thus can be used to compute the muon timing~\cite{Traczyk:1365029}.


    \insertFigure{figures/dtTiming} % Filename = label
                 {0.5}       % Width, in fraction of the whole page width
                 { A schema of few drift cells of DTs. The wires are shown as black dots, the drift direction as blue arrows, the expected hits as blue crosses and the reconstructed hits as the red crosses. The distance between reconstructed and expected hits is converted to time denoted as $\delta t$~\cite{Traczyk:1365029}. The assumed time when a in-time particle ($t_{IP} = 0$) would enter the drift cell is denoted as $t_{cell}$ and the time when the charges were read by a wire as $t_{read}$. In the left corner two situations are shown, either the muon was produced in-time and zero $\delta t$ is observed or the muon was not produced in-time ($t_{IP} \neq 0$) leading to the non-zero $\delta t$. }

The timing measurements are combined to produce, among others, the following variables: 

\begin{description}
\item [$\mathbf{time_{IP}^{InOut}}$]
This variable corresponds to the time at which a muon was present at the interaction point, assuming that the muon moves at the speed of light from the IP outside of CMS. It is computed as a weighted average $\bar{t}$ of the measured $\delta t$ values, where in case of the DTs each weight is equal to $N_{s}-2$, with $N_{s}$ being the number of hits in the segment of DTs to which the given hit belongs. The formula is then
\eq{timingResol}
{
 \bar{t} = \frac{1}{N} \times \frac{1}{\sum{N_{s,~i} - 2}} \times \sum{ (N_{s, i} -2) t_i },
}
where $N$ is the number of timing measurements $i$ and $t_{i}$ is a single timing measurement $\delta t$.

The error on the time measurement is computed as
\eq{timingResol}
{
 \sigma^{2} = \frac{1}{N-1} \times \frac{1}{\sum{w_{i}}} \times \sum{(t_i-\bar{t})^2 w_{i} },
}
where the weight $w_{i}$ is defined as $w_i = 1/\sigma_{i}^2$ with $\sigma_{i}$ being a single hit resolution and $\bar{t}$ is the above defined weighted average of the $\delta t$ measurements.

\item[$\mathbf{time_{IP}^{OutIn}}$ ]
The $time_{IP}^{OutIn}$ is the muon time at the interaction point assuming that the muon moves from the outside of the CMS detector towards the IP. During the calculation, each $\delta t$ measurement is increased by twice the time-of-flight~(TOF) of the in-time muon from the IP to the DT cell measuring the $\delta t$ to take into account that OutIn muon which was at IP at the same time as InOut one arrived to the DTs twice TOFs before the InOut muon. Then the computation of timing continues as for the $time_{IP}^{InOut}$.

\item[\textbf{Direction}]
The direction variable provides a simple and robust estimate if the muon traveled from the IP out or in the opposite way. The evaluation takes into account the errors on the $time_{IP}^{OutIn}$ and $time_{IP}^{InOut}$ variables and assumes that the correct time hypothesis has the smallest error.

\item[\textbf{Free} $\mathbf{1/\beta}$]
The free inverse beta (free $1/\beta$) variable is the free $c/v$, where $c$ is the speed of light and $v$ the speed of the muon.  It is obtained from the fit of muon time-of-flight measurements. The word ``free'' indicates that neither the production time, the direction nor the velocity is assumed and that all three are free parameters. The muons originating from collisions reaching the muon chambers, travel from inside towards outside of detector at speed close to the speed-of-light and therefore their free inverse beta is close to one. The free inverse beta for cosmic muons is around minus one due to the opposite direction.

The timing resolution for DTs is further discussed in Chapter~\ref{ch:simu}.

%The timing resolution for DTs in Run~I was determined to be 7-9~ns~\cite{Traczyk:1365029}, compared to 2.3~ns obtained from simulation. The measured resolution is expected to decrease as the detector synchronization improves.

\end{description}
%-on top of it
 %CMS being synchronized "top-down" for cosmic runs, so that a cosmic muon going vertically down is always in-time (or "at the same time" to be more precise). So basically the DT system is timed for muons going straight down. (just like for collisions it's timed for muons going outwards from IP).In practical terms. The "muons" collection takes as timeAtIpInOut what is more or less the mean of the segment times for a muon. Because it's assuming that the muon is propagating in the same direction that the system is synchronized in. From my observations above it looks like this is the case, the system is synchronized for downward-going cosmics. - not the case in the paper

\subsection{Trigger and data acquisition}

As bunches are colliding every 25~ns, thus with a rate of 40~MHz, fast and reliable triggering system~\cite{Khachatryan:2016bia} is required. The data size of one event is approximately 1~MB, therefore if there would not be any dedicated trigger, 40~TB of data per second would have to be stored, what is far beyond the current technical capacities. In CMS there are two levels of triggers which provide physics motivated selection of the interesting events. The first one, called Level-1~(L1), is hardware based and its decision-making is based on information from the muon chambers and the calorimeters. The L1 is capable to take a decision within 3.4~$\mathrm{\mu s}$ and its output rate is up to around 100~kHz. The rest of the event is read upon the decision of the L1 and sent to the second level called High Level Trigger~(HLT). The HLT is a software based trigger providing further selections. At the HLT level information from all subdetectors is read and therefore the full event can be reconstructed. The output rate of the HLT is around 1~kHz. The time period of uninterrupted data-taking is called a run and ideally there is one run per a LHC fill. In case of the detector technical difficulties the run can be interrupted and a new one started. Once the beams are dumped the run is stopped and a new run of cosmics instead of collision data-taking can start.

%The trigger can be set to select different kind of events. In case of Zero Bias trigger there is no requirement. In the Minimum Bias events, the trigger is firing on any bunch crossing with minimal requirement on the activity in the detector. More dedicated trigge triggerr is for example Single Muon trigger, which requires presence of one muon. 

During collision runs, most of the triggers are dedicated to record events useful for the physics analyses (Single Muon, \MET, Double Muon, ...). Part of the triggers can be used for calibration purposes, such as the Zero Bias and Minimum Bias triggers which fire on any bunch crossing leading to a minimal activity in the detector.

\subsection{Luminosity and pileup}

In particle physics experiments it is very important to have information about an expected event rate during a time period. For this evaluation, the following formula can be used

\eq{nev}
{
 \frac{\mathrm{d}N}{\mathrm{d}t} = \sigma \times \mathcal{L},
}
where $\sigma$ is the cross section of process of interest and $\mathcal{L}$ is the instantaneous luminosity given by

\eq{luminosity}
{
 \mathcal{L} = \frac{N^2 f}{4 \pi \epsilon_{n} \beta^{*}}F,
}
where the variables in numerator are $N$ which is the number of protons in one bunch (around $10^{11}$) and $f$ is the bunch crossing frequency (currently 40$\times 10^{6}$~Hz). In the denominator, $\epsilon_{n}$ is the normalized transverse beam emittance and $\beta^{*}$ is the beam amplitude function at the IP. This function is expressing how much the beam is ``squeezed'' before collision, lower the $\beta^{*}$ more the beam is squeezed. At LHC, the  $\epsilon_{n}$ is of the order of 4~mm~$\mathrm{\mu m}$ and $\beta^{*}$ of the order of 0.5~m. Lastly, because of the beam crossing angle, the reduction factor $F$ is introduced. Its value at LHC is typically around 0.95.

By integration of the instantaneous luminosity over time, the integrated luminosity can be obtained:

\eq{intluminosity}
{
 L = \int{ \mathcal{L} \mathrm{d}t}.
}

The LHC was designed to deliver an instantaneous luminosity of $1 \times 10^{34} \mathrm{cm^{-2}s^{-1}}$. At the beginning of Run~1, the instantaneous luminosity was lower than that and it has been increased during the years of LHC operation. Later, because of the smooth running, it was decided to go even beyond the designed luminosity, up to $1.58 \times 10^{34} \mathrm{cm^{-2}s^{-1}}$~\cite{Pralavorio:2272474}. The integrated luminosity delivered to CMS over years 2010--2017 can be seen in Fig~\ref{fig:figures/cmslumi}~\cite{website:CMSlumi}. A large fraction of integrated luminosity is good to be used in the physics analyses, the rest is being discarded due to a detector problem, for example. 


    \insertFigure{figures/cmslumi} % Filename = label
                 {0.6}       % Width, in fraction of the whole page width
                 { The delivered luminosity to the CMS detector for years 2010-2017~\cite{website:CMSlumi}. }


High luminosity is essential to study rare processes, but on the other hand it results in effect called pileup~(PU)~\cite{Bayatian:2006nff}. Pileup particles are particles which are not originating from the interaction of interest at a given bunch crossing. The pileup can be divided into two categories, in-time and out-of-time pileup. The in-time pileup is caused by multiple pp interactions in the event, the maximal peak in-time PU for all data-taking eras of 2017 is shown in Table~\ref{tab:PU}.  The out-of-time pileup~(OOT PU) originates from particles produced before or after the bunch crossing of interest. The OOT PU is caused for example by slow particles looping in the detector for more bunch crossings or due to the duration of integration of the signal charge by the front-end electronics, resulting in the pulse shape which is typically longer than 25~ns, depending on the subdetector. Because of the wide signal pulse shape, the signal from one particle can be read during more bunch crossings.

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|c|}
\hline
Era & Peak PU [interactions/BX]  \\
\hline
A & 9.523  \\
B & 46.035  \\
C & 47.162  \\
D & 59.019  \\
E & 70.478  \\
F & 77.978  \\
G & 4.534  \\
H & 61.603  \\
\hline
\end{tabular}
\caption[Table caption text]{The maximal peak in-time PU for all eras of 2017 data-taking. }
\label{tab:PU}
\end{center}
\end{table}
\newpage

\section{Event and object reconstruction at CMS~\label{sec:objects}}

The events triggered by the HLT are saved in RAW data format which contains the raw information from the detector processed by the HLT. The data in the RAW format are then processed in order to reconstruct physics objects. The output of such reconstruction is saved in the RECO format. Most physics analyses do not need all the information present in the RECO files, and thus these files are slimmed to up to a miniAOD~\cite{Petrucciani:2029414} format in order to save space and computing time (in 2017, there is an effort to slim even further the size of the data, going from miniAOD to nanoAOD format). In this section several physics objects, which are important for the analyses discussed in this thesis, are introduced.


\subsection{The Particle-Flow algorithm}

As it can be seen in Fig.~\ref{fig:figures/CMStransverse}~\cite{Sirunyan:2017ulk} each kind of particle leaves a characteristic signature in the CMS detector. For example, an electron leaves a track in the tracker and then stops in the ECAL where it deposits the rest of its energy. The neutral hadron does not interact in the tracker but can leave energy both in ECAL and then HCAL where it stops.

    \insertFigure{figures/CMStransverse} % Filename = label
                 {0.9}       % Width, in fraction of the whole page width
                 { Transverse view through a sector of the CMS detector. The depositions of different particles in different subdetectors are indicated in the picture~\cite{Sirunyan:2017ulk}. }

The CMS approach to reconstruct an event takes this into account and combines information from all subdetectors at once to reconstruct the objects. The algorithm used for this kind of reconstruction is called the Particle Flow~(PF) algorithm~\cite{Sirunyan:2017ulk}. In general, the deposits left by the particle in the different subdetectors are connected by geometrical constraints.


\subsection{Leptons}

\subsubsection{Muons}

Muons are traversing the whole CMS detector and therefore their tracks can be reconstructed in both the silicon tracker and the muon chambers. The ``standalone muon'' is a muon track reconstructed from the hits in CSC, DT and RPC, while the ``inner track'' muon is reconstructed from the hits in the silicon strip tracker only. There are two options how to reconstruct muon using both information from the muon chambers and the tracker. The first one leads to the collection of muons called ``tracker muons''.  The tracker muons are first reconstructed in the tracker and then they are extrapolated to the muon chambers by matching the inner track with hits in the muon chambers. The second approach matches the standalone muon with an inner track based on geometrical criteria. The resulting collection is called ``global muons''~\cite{Chatrchyan:2012xi}. 

The PF algorithm uses both global and tracker muons to identify a PF muon. The leptons originating from the hard scattering are decay products of e.g. W,Z and H boson (prompt muons) and therefore they are not expected not to have any other activity in the proximity. A requirement on muon isolation is added in order to select a muon and reject jets misidentified as muons or muons from decay of heavy flavor quarks. The selected muons are then tested by several quality requirements to balance the efficiency and purity of the muon selection. Based on passing given criteria, several muon identifications (IDs) are assessed, e.g. loose, medium, tight. Muons are being reconstructed up to $|\eta|=2.4$ with a reconstruction and identification efficiency larger than 96\%. The muon trigger efficiency is higher than 90\%. Using information from both tracker and muon chambers the \pt resolution for muons with 20 <\pt < 100~GeV is 1.3--2.0\% in the barrel region and more than 6\% in the endcaps. For muons with \pt up to 1~TeV the transverse momentum resolution does not go above 10\%~\cite{Chatrchyan:2012xi}.

\subsubsection{Electrons}

The electrons are reconstructed with the track information from the tracker and the energy deposits in the ECAL~\cite{Khachatryan:2015hwa}. Because of bremsstrahlung, an electron looses in average around 30\% of its energy before reaching the ECAL. The energy deposit in the ECAL is reconstructed as a supercluster, taking into account the bremsstrahlung photons. The electron track in the tracker is reconstructed by the GSF algorithm~\cite{Adam:2003kg} starting either from the seed created by a few tracker hits or from the ECAL supercluster and then the track is extrapolated from the seed to the full tracker. In case of a tracker-based seeding, the next step is to match the ECAL supercluster with the electron track. Similarly as for the muon, an isolation criterion is requested for the prompt electron as well as quality requirements on the reconstructed electrons are imposed resulting in several categories of electron IDs e.g. loose, medium, tight.

Electrons are reconstructed up to $|\eta|=2.5$,  with an efficiency higher than 88\% in the \pt range from 10~GeV to 100~GeV and $|\eta|<2$. The energy measurement in ECAL and momentum measurement in tracker are used to estimate the momenta of electrons. The resolution on the momentum measurement is evaluated from $Z \rightarrow ee$ decays and its is between 1.7\%-4.5\% for electrons with  \pt~$\approx$~45~GeV~\cite{Khachatryan:2015hwa}.



\subsubsection{Taus}

In around 2/3 of cases the tau leptons are decaying hadronically to a mixture of charged and neutral hadrons and tau neutrino. The decay is very fast and thus it is difficult to reconstruct the secondary vertex. The algorithm which is used to recognize the hadronically decaying tau is called Hadron-Plus-Strips~(HPS)~\cite{CMS:2016gvn}. This algorithm searches for the neutral pions present in the majority of hadronic tau decays. The neutral pion, originating from tau, decays to a photon pair, the photons later converting to an electron/positron pair. These electrons/positrons bend in the magnetic field and thus broaden the energy deposits in the ECAL in azimuthal direction beyond the size of the reconstructed hadronic tau jet. To take this affect into account, the electromagnetic particles  are reconstructed into fixed size $\Delta \eta \times \Delta \Phi$ window called ``strip''. The strip is first associated with the most energetic electron or photon within the PF jet. Then the algorithm looks within the given window whether other electromagnetic particles are present close to the selected one. If yes, the particle is added to the strip. The algorithm proceeds up to the point when no other electromagnetic particle is present in the $\Delta \eta \times \Delta \Phi$ strip. Then the most energetic electromagnetic particle not belonging to any strip is associated to a new strip and the algorithm proceeds as before. The final algorithm searches for the hadronic taus in topologies with a single hadron, one hadron and one strip, one hadron and two strips, and three hadrons. The probability to misidentify a jet, an electron and a muon as an hadronic tau in data depends on the objects identification requirement and was measured to be around 0.01\%-4\%, 0.1\%-3\%, 0.03\%-0.3\%, respectively. Large differences were found in misidentification rate between data and simulation, leading to data to simulation ratio up to 1.66 in the case of electron and 1.86 in the case of muon. The hadronic tau identification efficiency is of around 50-60\% and is similar for data and simulation~\cite{Khachatryan:2015dfa}.

%The tau identification efficiency is measured in perspective of deriving data to simaltion scale factors. These factors vary from 0.83 to 0.96, depending on the tau identification technique.


\subsection{Photons}

Photons do not leave tracks in the tracker and thus their energy is obtained only from ECAL measurements. The prompt photon identification is based on two categories of observables, its shower shape and isolation from the remaining activity in the ECAL. Again, three photon identifications (IDs) are defined: loose, medium and tight. Achieved photon energy resolution in the barrel region is between 1\%-2.5\% for photons with energy of tens of GeV. In the endcaps the photon energy resolution is of 2.5\%-4\%~\cite{CMS:EGM-14-001}.

\subsection{Jets}

The jets are objects originating from the hadronization of quarks and are clustered with the $\mathrm{anti-}k_{T}$~(ak) clustering algorithm~\cite{Cacciari:2008gp, Cacciari:2011ma}. Within this algorithm the distance between objects is defined as

\eq{antikt}
{   
    d_{ij} = \mathrm{min}({p_{T}}^{-2}(i), {p_{T}}^{-2}(j)) \frac{(\eta_{i} -\eta_{j})^2+ (\Phi_{i} -\Phi_{j})^2}{R^2} =  \mathrm{min}({p_{T}}^{-2}(i), {p_{T}}^{-2}(j)) \frac{\Delta R_{ij}^{2}}{R^2},
}
where $p_{T}(i)$ is the transverse momentum, $\eta_{i}$ is the pseudorapidity and $\phi_{i}$ is the azimuthal angle of the object $i$. To reconstruct PF jets, the algorithm runs over PF reconstructed objects such as electrons, muons, photons, charged and neutral hadrons. The parameter $R$ is a jet radius parameter and for the standard jet reconstruction of Run~2 its value is set to 0.4. In the Run~1 this parameter was chosen to be 0.5. In case of boosted objects decaying to partons, two or more jets originating from boosted parton can be merged. These topologies can be reconstructed as so called ``fat jets'', and for purpose of their reconstruction, the parameter $R$ is increased to 0.8 or 1.0. The $\mathrm{anti-}k_{T}$ algorithm, by definition, clusters first the hard objects with the shortest distance between each other and continues with objects further apart. The clustering stops when no hard enough particle is nearby. The product of the clustering is a jet. The charged component of the jet can be reconstructed only up to $|\eta|=2.4$ due to the tracker coverage, while the neutral component extends up to  $|\eta|=5$.

The measured jet energy does not in general correspond to the energy of parton responsible for the jet, because of several inefficiencies and biases in the energy measurement. Therefore the jet energy must be calibrated and re-scaled by a correction factor in order to have a correct jet energy scale. The jet energy corrections are obtained from simulations. Additional jet energy scale correction is derived from measured dijet, photon+jet, Z+jet, and multijet events to take into account differences between data and simulation~\cite{Khachatryan:2016kdb}. The typical PF jet energy resolution is around 15\% for 10~GeV jets, 8\% for 100~GeV jets, and 4\% for 1~TeV jets. %from page det 

\subsection{b-jets}

In order to know from which quark the jet is originating, flavor tagging techniques were developed. The target of the heavy flavor tagging techniques is to recognize jets originating from a b quark~(b-jets) or a c quark~(c-jets). In the following, only b-jets are discussed. The b-quarks are forming B-mesons, which decay within about 1.5 ns creating a secondary vertex  displaced by few mm up to cm from the primary vertex. The information on a displaced secondary vertex or displaced tracks in the jet, information about particles originating from the secondary vertex and optionally information on soft leptons within the jet are used by b-tagging algorithms to tag jets formed from the b-quarks~\cite{Sirunyan:2017ezt}. Due to the tracker geometry, b-jets can be reconstructed only up to $|\eta|=2.4$.

There are several algorithms, whose purpose is to tag a b-jet. The first one is the Combined Secondary Vertex~(CSVv2) algorithm, which combines information about displaced tracks with information on the secondary vertex. The DeepCSV algorithm improves the performance with respect to the CSVv2 algorithm by using a deep neural network. The Combined Multivariate Analysis~(cMVAv2) technique takes into account a fact, that B-hadrons can decay leptonically and thus soft electrons or muons can be present in the b-jet. In this algorithm, the information about soft leptons is used in combination with other taggers. The efficiency to tag a b-jet versus the probability to misidentify a c or light flavor jet as a b-jet for different taggers is shown in Fig.~\ref{fig:figures/btag}~\cite{Sirunyan:2017ezt}. The performances of taggers were evaluated from simulation.


    \insertFigure{figures/btag} % Filename = label
                 {0.7}       % Width, in fraction of the whole page width
                 { The probability to misidentify a c or light flavor jet as a b-jet versus the efficiency to identify a b-jet for different b-tagging algorithms. These curves were evaluated from simulated $t\bar{t}$+jets events, using jets with \pt > 20 GeV~\cite{Sirunyan:2017ezt}. }

%The performance of b-jet taggers is different in data and event simulations therefore a multiplicative data-to-simulation factor must be used on top of the simulation in order to compensate for the differences.

\subsection{Missing transverse energy}


If the momenta of all particles could be measured, the sum of all momenta in the plane transverse to the beam would be zero due to the momentum conservation law. But as neutrinos escape the detector undetected, an imbalance of momentum in this plane is observed. 

The Missing Transverse Energy~($E_{T}^{miss}$) is the magnitude of the negative vectorial sum of the transverse momenta of all PF particles~\cite{CMS:2016ljj}. Because of the energy thresholds in the calorimeters, inefficiencies in the tracker or non-linearity of calorimeters' response for hadrons, the \MET measurement can be biased and thus an energy correction factor must be used. This factor accounts for effects influencing the \MET and is applied on the transverse momenta of the jets. The \MET is then recomputed with the new transverse momenta of jets. The uncertainty on \MET is evaluated by varying the $p_{T}$ of each kind of object within its resolution. The  \MET  distributions for  $Z \rightarrow ee$ and $Z \rightarrow \mu \mu$ events are shown in Fig.~\ref{fig:figures/met}~\cite{CMS:2016ljj}. These plots show a good agreement between data and simulation. The $Z \rightarrow ee$ and $Z \rightarrow \mu \mu$ events have no genuine source of the \MET , no neutrino in the final states. Therefore the \MET is expected to be zero, but due to the \MET resolution, non-zero values are observed.  


    \insertFigure{figures/met} % Filename = label
                 {0.9}       % Width, in fraction of the whole page width
                 { \MET distributions for $Z \rightarrow \mu \mu$~(left) and $Z \rightarrow ee$~(right) events with the data to simulation ratio in bottom. There is also a contribution from two other groups of processes decaying to the dimuon or dielectron final states. The Top contribution originates from the $t\bar{t}$ and single top processes, in which the W-bosons decay leptonically to charged lepton and neutrino and therefore these events have a genuine source of the \MET. The EWK group of processes consists of diboson, $Z\gamma$ and $W\gamma$ production processes, which are also partly present in the \MET tail due to leptonically decaying W-bosons in some of them~\cite{CMS:2016ljj}. }

The \MET variable plays a crucial role in searches for the physics beyond the Standard Model, as many theories predict stable weekly interacting particles which would enhance the \MET.



