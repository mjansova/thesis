\clearpage

\setcounter{secnumdepth}{4}
\chapterwithnum{The CMS experiment at the LHC~\label{sec:detch}}
\setcounter{secnumdepth}{5}

There are several options how to study elementary particles, for example it can be studied via cosmic rays, astrophysical neutrinos, direct searches for the dark matter or at collider experiments. In Section~\ref{sec:LHC} the largest existing collider, the LHC, and its experiments are introduced. In Section~\ref{sec:CMS} the CMS detector, in which context this thesis is performed, is described. Then in Section~\ref{sec:objects}, the object reconstruction techniques of the CMS collaboration applied on the CMS data are introduced. A special interest is put on the topics whose a deeper understanding is required for the following chapters of this thesis.

\section{The Large Hadron Collider~\label{sec:LHC}}

The Large Hadron Collider~(LHC)~\cite{Evans:2008zzb} is a particle accelerator with a circumference of 27~km, which is a part of the CERN accelerator complex~\cite{Bruning:2004ej} located near Geneva, Switzerland. The LHC project was approved in 1994 and designed to provide mainly collisions of protons. Part of the LHC operation time is also dedicated to collisions of heavy nuclei, but in this thesis only the proton collisions are described.

A schematic view of the CERN accelerator complex with its main experiments is presented in Fig.~\ref{fig:figures/CCC-v2016}~\cite{Mobs:2225847}. At the beginning of the acceleration process the protons are obtained by stripping electrons from the hydrogen atoms. Protons are then accelerated through a chain of accelerators: Linac2, Booster, Proton Synchrotron~(PS) and Super Proton Synchrotron~(SPS). The proton beams accelerated to 450~GeV are injected from the SPS into the LHC using separate pipes, one beam turning clockwise and the other one anti-clockwise. In the LHC, the beams are further accelerated with eight radio-frequency~(RF) cavities per beam, currently to the beam energy of 6.5~TeV. The LHC is equipped with 9593 magnets, mainly dipoles and quadrupoles, to bend and focus the beams. There is an ultrahigh vacuum of order of $10^{-10}-10^{-11}$~mbar in the LHC tube to avoid collisions of particles with gas. A vacuum of around $10^{-6}$~mbar is also used for the isolation  of cryomagnets and the helium distribution line.

    \insertFigure{figures/CCC-v2016} % Filename = label
                 {0.99}       % Width, in fraction of the whole page width
                 { The CERN accelerator complex~\cite{Mobs:2225847}. }

The proton beams are not homogeneous but composed of trains of bunches, each bunch containing around 100 billions of protons. Bunches within a given train are spaced by 25~ns. Time gaps between two different trains are longer, their duration depends on the beam structure and \textcolor{red}{currently it starts from seven times 25~ns}. The LHC uses several beam structures, which are specified by the filling scheme. An example of a beam structure is shown in Fig.~\ref{fig:figures/beamStructure}. 

Up to now, the LHC operation has been divided into two eras, Run~1 and Run~2. The Run~1 started in 2008 and ended in 2013. During this era the center-of-mass energy of the pp collisions was first 7~TeV, then it was increased to 8~TeV in 2012, and the beam structure allowed collisions every 50~ns. The Run~2 started in 2015 and is still ongoing. In the Run~2 the collision center-of-mass energy increased to 13~TeV and the time between collisions was reduced to 25~ns. The Run~2 stops at the end of 2018, the Run~3 is scheduled to start in 2021.

    \insertFigure{figures/beamStructure} % Filename = label
                 {0.8}       % Width, in fraction of the whole page width
                 { (top) An example of beam structure. The beam pipes are shown in red and violet and the beams are drawn in green. (bottom) An example showing the structure of two trains. }

The bunches of protons collide at four interaction points (IP), at which four main experiments are installed. The two general-purpose detectors, which are designed to cover a wide range of physics, are ATLAS (standing for ``A Toroidal  LHC ApparatuS'')~\cite{Aad:2008zzm} and CMS (standing for ``Compact Muon Solenoid'')~\cite{Chatrchyan:2008aa}. The other two main experiments are ALICE (standing for ``A Large Ion Collider Experiment'')~\cite{Aamodt:2008zz}, mainly focusing on the physics of heavy-ion collisions and the study of the ``quark-gluon plasma'' which existed at the early Universe, and the LHCb (standing for ``Large Hadron Collider beauty'')~\cite{Alves:2008zz} specialized in the physics of the b-quark. There are also three smaller experiments along the LHC, one of them is TOTEM~\cite{Anelli:2008zza} which is close to CMS and its principal goal is to measure the total cross section of protons at the LHC. LHCf~\cite{Adriani:2008zz}, which is located near to the ATLAS experiment, studies particles moving very close to the proton beams. Finally MoEDAL~\cite{Acharya:2014nyr}, which is close to LHCb, focuses on the search of hypothetical particles, e.g. magnetic monopoles.

One of the main motivations for the LHC and its experiments was the search for the Higgs boson. After its discovery in 2012 by the ATLAS and CMS collaborations, the measurement of the Higgs boson properties has now entered into the physics program. A second important topic of research is the search for new particles and more generally for evidence of physics beyond the Standard Model, motivated mainly by cosmological observations, naturalness of the Higgs mass and the desire for unification of known interactions.

%\newpage

%TODO here

\section{The Compact Muon Solenoid detector~\label{sec:CMS}}

%The CMS (``Compact Muon Solenoid'') detector~\cite{Chatrchyan:2008aa, CMSproposal} is a multipurpose detector of overall length of 22~m, a diameter of 15~m and a weight of 14~t, located at the IP~5. The designed properties of the CMS  detector were to have high efficiency of muon identification and reconstruction. It was also required have precise momentum resolution in large range of momenta, dimuon mass resolution of order of 1\% at 100 GeV, good charged-particle momentum measurement and resolution~(around 1\%-2\% for 10~GeV muons in majority of CMS coverage) as well as high efficiency in reconstruction of charged-particle tracks. Furthermore it was designed to have precise measurement electromagnetic energy, leading to resolution of diphoton and dielectron mass of around 1\% at 100~GeV. Good missing transverse energy~(MET) and dijet mass resolution was required as well. One of the important requirements was also high efficiency in offline tagging of tau particles and jets originating from b-quarks. These conditions have to be fulfilled in the LHC environment, with a bunch crossing~(BX) frequency of 25~ns, where every bunch crossing leads to tens of inelastic interactions on top of the interaction of the interest, referred to as ``pileup''~(PU), resulting in thousands of charged particles in the CMS detector every 25~ns. Because of this large radiation, the detectors and front-end electronics have to be radiation-hard.

The CMS (``Compact Muon Solenoid'') detector~\cite{Chatrchyan:2008aa} is a multipurpose detector of an overall length of 22~m, a diameter of 15~m and a weight of 14~t, located at the IP~5. The designed properties~\cite{CMSproposal} of the CMS  detector were to have high a quality tracking providing precise charged-particle momentum measurement and resolution around 1\%-2\% for 10~GeV muons in the majority of the CMS coverage being $\abs{\eta}<2.4$ and to have high efficiency of muon identification and reconstruction, leading to a requirement on  a dimuon mass resolution of the order of 1\% at 100 GeV. Furthermore it was designed to have the best possible measurement of the electromagnetic energy, leading to a resolution of diphoton and dielectron masses of around 1\% at 100~GeV. These conditions have to be fulfilled in the LHC environment, with a bunch crossing~(bx) every 25~ns, where every bunch crossing leads to tens of inelastic interactions on top of the interaction of the interest, referred to as ``pileup''~(PU), resulting in thousands of charged particles in the CMS detector every 25~ns. Because of this large radiation, the detectors and front-end electronics have to be radiation-hard.

To achieve the given requirements, CMS was built in layers around a large solenoidal magnet, with endcaps at each side. The CMS magnet is a superconducting solenoid providing a magnetic field of 3.8~T. The magnet is surrounded from outside by the steel yoke which returns the magnetic flux of the solenoid~\cite{tdrMagnet}. The radius of the magnet has to be kept relatively small and therefore the available space between the magnet and interaction point is limited.

Inside the magnet from the interaction point outwards, there is a pixel and silicon strip tracker, followed by the electromagnetic and hadron calorimeters. Outside of the magnet there is the outer hadron calorimeter and the steel return yoke with embedded muon chambers. The CMS detector layout is shown in Fig.~\ref{fig:figures/cmsdetector}~\cite{website:CMSdet}. In the following sections, first the coordinate system of the CMS is described. Then the CMS subdetectors are introduced, starting from the innermost one. At the end, basic information on trigger, luminosity and pileup is given.
%-coverage up to |eta|<5


    \insertFigure{figures/cmsdetector} % Filename = label
                 {0.99}       % Width, in fraction of the whole page width
                 { A schematic layout of the CMS detector~\cite{website:CMSdet}. }

\subsection{Coordinate system and conventions}


The coordinate system used by CMS~\cite{Chatrchyan:2008aa} is sketched in Fig.~\ref{fig:figures/coordinates}~\cite{Pantaleo:2293435}. In the CMS conventions, the cartesian coordinate system is centered at the IP, with the x-axis pointing into the center of the LHC, the y-axis going upwards and the z-axis going anti-clockwise along the beam direction. The azimuthal angle $\Phi$ is defined in the x-y plane and is measured from the x-axis. The polar angle $\theta$ is measured from the z-axis and is defined in the y-z plane. Finally $r$ is a radial coordinate in the x-y plane. In this convention the pseudorapidity $\eta$ is defined as

\eq{pseudorapidity}
{
    \eta =  -\ln \left[ \tan \left( \frac{\theta}{2} \right) \right].
}

The angular distance between two points can be measured with the help of $\Delta R$ defined as

\eq{deltaR}
{
    \Delta R = \sqrt{ \Delta \Phi^2 + \Delta \eta^2}.
}


The transverse momentum $p_{T}$ can be computed from the x and y momentum components as

\eq{pseudorapidity}
{
    p_{T} =  \sqrt{p_{x}^2 + p_y^2 }.
}

\textcolor{red}{At the interaction point, the partons in proton beams have negligible momentum in the x-y plane, and therefore  } the sum of momenta of all particles originating from the collision in this plane should be zero due to momentum conservation law. Therefore an imbalance of momenta in this plane, i.e. a non-zero total $p_{T}$, can be a sign of particles whose momentum is unmeasured, like neutrinos or hypothetical new particles. 

    \insertFigure{figures/coordinates} % Filename = label
                 {0.6}       % Width, in fraction of the whole page width
                 { The CMS coordinate system with the three axes intercepting at the interaction point, the x-axis pointing inside the LHC ring, the y-axis going upwards and the z-axis pointing anti-clockwise along the beam~\cite{Pantaleo:2293435}. }

\subsection{The silicon tracker~\label{sec:tracker}}

The silicon tracker~\cite{CMS:1997tlf, CMS:2000eqx} is the innermost subdetector of the CMS detector. The CMS tracker is divided into two parts, the inner (outer) part consists of a pixel (strip) detector.  Its purpose is to reconstruct tracks from charged particle depositions, energy losses $E_{loss}$, in silicon sensors. In order to recognize from which interaction a given particle originates, the tracker is required to have a capability to reconstruct primary and secondary vertices. The reconstruction of primary vertices targets to find the positions where the interaction of interest or the PU interaction occurred. The primary vertices are determined by the vertex fitting procedure from the tracks~\cite{Ball:2007zza}. The goal of the secondary vertex reconstruction is to spot the place where a particle with a long lifetime decays to other particles. 

On the tracker level, the tracking is performed in 4 steps~\cite{website:slidesTracking, website:twikiTracking}. It starts from  hits reconstructed from particle depositions in the sensors. First, the \textit{track seeding} is performed from three 3-D reconstructed hits \textcolor{red}{ in pixel and/or strip tracker} or two of them with a constraint on the beam spot. Then the algorithm proceeds with \textit{track building} which aims to connect all hits originating from one particle. During the track building the track is propagated to the neighboring layers of the tracker, testing the compatibility of the reconstructed hit with the track by a $\chi^{2}$ test. Once the full track candidate is complete, the \textit{track fitting} is performed to obtain the best parameters of the track and to recompute precisely the hit position using the track properties. The last step is a \textit{track quality selection} rejecting tracks not fulfilling quality requirements, which are based on the $\chi^{2}$ of the final fit, the number of layers with a hit associated to the track and the probability of the track  to originate from the primary vertex.

The default track reconstruction~\cite{Chatrchyan:2014fea} is using the software referred to as the Combinatorial Track Finder~(CTF), based on the combinatorial Kalman filter~\cite{Fruhwirth:1987fm}. The tracking uses an iterative approach: in the first iteration the easiest tracks to find are reconstructed (i.e. the ones with the highest $p_{T}$), then after these tracks are complete their hits are masked in order to avoid duplicities and reduce combinatorics for further iterations of tracks finding. In total there are 12 iterations and each iteration is focused on a specific type of tracks.


Due to the presence of the magnetic field, charged particles are bent according to their momentum and charge, thus the CMS tracker is able to measure the charge sign and the momentum associated to a track. To perform so, the tracker needs to have a good spatial resolution. It has to be as well extremely radiation-hard due to the large flux of incoming particles. Also the material was chosen carefully, in order to reduce multiple scattering, nuclear interactions or bremsstrahlung in the tracker material.

The flux of particles in the CMS detector decreases with the distance from the interaction point, the flux of charged particles in the barrel at a radius of 4~cm is around $10^{8}~\mathrm{cm^{-2}s^{-1}}$ while at a radius of 115~cm it decreases to around $3 \times10^{5}~\mathrm{cm^{-2}s^{-1}}$. Consequently, the inner part of the tracker is made of silicon pixels, which are able to measure particle paths and their properties in a high particle density environment. Moreover a good resolution is needed for the vertex determination. In the outer part of the tracker, the particle density is low enough to use silicon strip sensors, which are cheaper mainly because they require less readout channels. Overall, the tracker pseudorapidity coverage is  $|\eta| < 2.5$.


\textbf{The silicon pixel tracker}

%The silicon strip tracker is 5.8~m long with a diameter of 2.5~m. 
Before 2017, the pixel barrel, referred to as BPIX,  was located at a radius of 4.4~cm up to 10.2~cm, from the IP. The pixel endcaps~(FPIX) extended on each side from 35~cm to 47~cm in the z direction. In total, there were three barrel layers and two endcaps layers on each side. During an extended winter shut-down in 2017, due to the high radiation exposure, the pixel tracker was replaced. The new pixel tracker has four barrel layers covering 3$\leq r \leq$16~cm and three endcap disks at distances  29.1$\leq \abs{z} \leq$51.6~cm. The pixel detector plays a crucial role in the track seeding, and the reconstruction of the primary and secondary vertices~\cite{CMS:2012sda}. 


%-new pixels - short distance from IP, high radiation -> damage -> need for replacement
%- FPIX - 3 disks on each side 29.1cm -51.6cm  (Forward pixel) ~\cite{CMS:2012sda}
%- BPIX - barrel pixel - 4 cylindrical layers radius of 3-16 cm

\textbf{Silicon strip tracker}

%15148 silicon strip modules

As the following chapters present studies of the silicon strip tracker and its simulation, let take now a deeper look into its design and properties. The silicon strip tracker is divided into four partitions. Each partition is composed by several layers of modules, which have either one side~(mono) or two sides~(stereo) of silicon sensors. In total the strip tracker is composed of 15148 modules. The Tracker Inner Barrel~(TIB) is the innermost barrel part with two layers of stereo modules succeeded by two layers of mono modules. The Tracker Outer Barrel~(TOB) surrounds the TIB. In the innermost part of TOB, there are two layers of stereo modules, the remaining four layers being mono. On each side of the barrel, Tracker Inner Disks~(TID) and Tracker EndCaps~(TEC) are located. There are three wheels (perpendicular to the z-axis) of TID with three module rings (parallel to the z-axis) and 9 wheels of TEC with four to seven rings of modules on each side. In each wheel there is a mixture of mono and stereo modules, but each ring has either mono or stereo modules. 

In the barrel region, the silicon tracker is placed in radius between 20~cm up to 1.1~m from the IP. The disks start at 80~cm in the z-direction from the IP and the endcaps reach up to z=2.8~m from the IP. The overall layout of the silicon strip tracker can be seen in Fig.~\ref{fig:figures/cmsTracker}~\cite{Chatrchyan:2014fea}.

    \insertFigure{figures/cmsTracker}
                 {0.9}       
                 {A schema of the longitudinal view of the upper half of the CMS silicon strip tracker and layout of its partitions. The star represents the IP. The modules in blue are stereo, while the mono ones are shown in black~\cite{Chatrchyan:2014fea}. }

Each mono module holds 320~$\mathrm{\mu m}$ or 500~$\mathrm{\mu m}$ thick silicon sensors with either 512 or 768 silicon strips.  The strip length range is from 8 to 25~cm. The distance between strips, called pitch, varies between around 80~$\mathrm{\mu m}$ and 200 ~$\mathrm{\mu m}$.  In the barrel, the strips are parallel to the z-axis, or tilted by 100~mrad with respect to the z-axis in case of the stereo sensors. In TID and TEC, the strips \textcolor{red}{are not parallel to each other and} are aligned to be parallel to $r$, \textcolor{red}{or tilted by 100~mrad with respect to the $r$ in case of the stereo sensors}. The strip width to pitch ratio is equal to 0.25.

The local module coordinates have their zero in the middle of the module, the z-axis going in the direction from the back-plane to the strips, the y-axis going along the strips, and the x-axis being perpendicular to the strips and traversing them. The local $\theta$ angle is measured from the z-axis. The local $\Phi$ is defined in the x-y plane and measured from the x-axis. The schematic view of the sensor local coordinates is shown in Fig.~\ref{fig:figures/localCoordinates}. The details about the module geometries for each layer of TIB and TOB and each ring of TID and TEC can be found in Table~\ref{tab:trackerGeometries}~\cite{website:hephyPage}.


    \insertFigure{figures/localCoordinates} % Filename = label
                 {0.6}       % Width, in fraction of the whole page width
                 { The sensor local coordinate system with the three axes intercepting in the middle of the sensor. The x-axis is perpendicular to the silicon and aluminium strips (represented by the dark gray bands on the top of the drawing), the y-axis goes along the strips and the z-axis points from backplane (represented at the bottom by the dark gray/green surface) to the strips. }

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Layer & Type  & \#Strips & Thickness~[$\mathrm{\mu m}$] & Pitch~[$\mathrm{\mu m}$] & Geometry label  \\
\hline
\hline
TIB L1 & stereo & 768 & 320 & 80 & IB1 \\
TIB L2 & stereo & 768 & 320 & 80 & IB1 \\
TIB L3 & mono & 512 & 320 & 120 & IB2  \\
TIB L4 & mono & 512 & 320 & 120 & IB2 \\
\hline
TOB L1 & stereo & 768/512 & 500 & 122/183 & OB2 \\
TOB L2 & stereo & 768/512 & 500 & 122/183 & OB2  \\
TOB L3 & mono & 512 & 500 & 183  & OB2 \\
TOB L4 & mono & 512 & 500 & 183  & OB2 \\
TOB L5 & mono & 768 & 500 & 122  & OB1 \\
TOB L6 & mono & 768 & 500 & 122  & OB1 \\
\hline
TID R1 & stereo & 768 & 320 & 81...112  & W1a \\
TID R2 & stereo & 768 & 320 & 113...143 & W2a  \\
TID R3 & mono & 512 & 320 & 124...158  & W3a \\
\hline
TEC R1 & stereo & 768 & 320 & 81...112 & W1b  \\
TEC R2 & stereo & 768 & 320 & 113...143 & W2b   \\
TEC R3 & mono & 512 & 320 & 124...158  & W3b \\
TEC R4 & mono & 512 & 320 & 113...139  & W4 \\
TEC R5 & stereo & 768 & 500 & 126...156  & W5 \\
TEC R6 & mono & 512 & 500 & 163...205  & W6 \\
TEC R7 & mono & 512 & 500 & 140...172  & W7 \\
\hline
\end{tabular}
\caption[Table caption text]{Module type, strip multiplicity, sensor thickness and pitch and module geometry label for layers or rings of the four silicon strip tracker partitions~\cite{website:hephyPage}. }
\label{tab:trackerGeometries}
\end{center}
\end{table}


The track resolution in \pt determined in 2011 before replacing the pixel detector, is of the order of 1.5\% for non-isolated particles in the range 1 < \pt < 10~GeV and $|\eta| < 1.4$ and of order of 2.8\% for particles with \pt = 100~GeV and $|\eta| < 1.4$~\cite{TRK-11-001}. \textcolor{red}{The performance in \pt resolution is comparable after the upgradei as before.} The spatial resolution of  reconstructed hits for different barrel layers of the strip tracker is shown in Fig.~\ref{fig:figures/hitResolution}~\cite{website:hitEff}: The typical strip hit resolution ranges between 15~and~45~$\mathrm{\mu m}$ in the barrel region of the silicon strip tracker.


    \insertFigure{figures/hitResolution}
                 {0.57}       
                 {Measured resolution of reconstructed hit position for different layers of the strip tracker and different size of pitch between the strips. The red color corresponds to hits with a charge deposited in one strip, green in two strips and blue in three strips~\cite{website:hitEff}. }

\subsection{The electromagnetic calorimeter}

The electromagnetic calorimeter (ECAL)~\cite{tdrECAL} is a subdetector located on the outer side of the silicon tracker. In the barrel region the ECAL extends up to a radius of 1.77~m from the IP. It is an homogeneous, fast, radiation resistant calorimeter with a good energy resolution. It is composed of 75848 lead-tungstate ($\mathrm{PbWo_{4}}$) crystals and its purpose is to measure the energy of electrons and photons. The ECAL consists of one barrel~(EB) covering $|\eta|<1.479$ and two endcaps~(EC) extending the coverage up to $|\eta| =3$. A preshower is placed in front of the endcaps in order to separate highly energetic single photons from the photons originating from the decay of neutral pions. \textcolor{red}{In the barrel part the ECAL has 25.8 radiation lengths in the radial direction, and in the endcap part 24.7 interaction lengths in z-direction. }

The energy resolution $\sigma_{E}$ of the ECAL was determined~\cite{Chatrchyan:2008aa} to be

\eq{ECALresol}
{
 \frac{\sigma_{E}}{E} = \frac{0.028}{\sqrt{E}} \bigoplus \frac{0.12}{E} \bigoplus 0.003 ,
}
where $E$ is the energy. The first term ($\propto 1/\sqrt{E}$) is the stochastic part, it corresponds to e.g. fluctuations in number of particles. The second term ($\propto 1/E$) accounts for noise and the third term (constant) covers mainly the non-uniformities, energy leakage and inter-calibration issues.


\subsection{The hadron calorimeter}

The purpose of the hadron calorimeter~(HCAL)~\cite{tdrHCAL} is to measure the energy of strongly interacting particles.  The HCAL is a sampling calorimeter composed of four parts, out of them two are located between the ECAL and the magnet, which are the HCAL Barrel~(HB) and Endcaps~(HE). Both HE and HB have a brass absorber and their active material is made of plastic scintillators. The pseudorapidity coverage of HB is $|\eta|<1.3$, and of HE $1.3<|\eta|<3$. \textcolor{red}{The length of HB in interaction lengths in radial direction is around 6, and of HE in z-direction of around 10.} The coverage is further extended up to $|\eta|=5.2$ by the third part called the Forward calorimeter~(HF). Installed 11.2~meters from the IP on both sides, the HF is made of steel as an absorber and quartz fibers creating the active volume. The technology of the HF is very radiation-hard as around one third of the particles produced in the collisions reaches HF. Because the available radial space between the ECAL and the magnet (i.e. in the region between r=1.77~m and r=2.95~m) is not large enough to build a calorimeter with enough stopping power, the last part of the calorimeter, the Outer calorimeter~(HO), was added after the magnet. The HO is covering the region $|\eta|<1.3$ and stops particles escaping the HB, for this reason it is sometimes also referred to as ``tail catcher''. The magnet material is in that case used as an absorber for the HO. A schematic layout of the HCAL is shown in Fig.~\ref{fig:figures/HCAL}~\cite{Chatrchyan:2008aa}.

    \insertFigure{figures/HCAL}
                 {0.7}       
                 {A schema of one quarter of the CMS HCAL with the layout of the HB, HE, HF and HO~\cite{Chatrchyan:2008aa}. }

The hadron energy resolution from the combination of the ECAL and HCAL (barrel and endcaps)~\cite{Chatrchyan:2009ag} was measured to be


\eq{HCALresol}
{
 \frac{\sigma_{E}}{E} = \frac{0.847}{\sqrt{E}} \bigoplus 0.074 ,
}
where the meaning of the terms is similar as for the ECAL.
%- for HF 1.98/sqrt(E)+0.09 -> higher because of high energy of jets in this region but as divided by energy, it is ok

\subsection{The muon chambers}

Because many interesting physics processes have a signature with muons in the final state, a good and precise measurement of muons is one of the main goals of CMS. This comprises muon identification, momentum measurement and triggering. The good triggering and momentum measurement is achieved with the help of the high magnetic field provided by the solenoid. The measurement of muons is done in three gaseous subdetectors, the Drift Tube~(DT), Cathode Strip Chamber~(CSC) and Resistive Plate Chamber~(RPC) systems~\cite{tdrMuon}. The combined three muon systems have in total 1400 chambers, which in radial direction are placed between around 4~m up to 7.5~m from the IP. The $\abs{z}$ positions of the inner and outer part of muon systems are about 5.5~m-11~m, respectively. The layout of the muon systems is shown in Fig.~\ref{fig:figures/muons}~\cite{Chatrchyan:2013sba}.

    \insertFigure{figures/muons}
                 {0.7}       
                 {A schematic longitudinal view of one quarter of the CMS muon systems and their inner structure~\cite{Chatrchyan:2013sba}. In case of DTs MB stands for ``Muon Barrel'' and in case of CSCs ME stands for ``Muon Endcap''. The notation for RPCs is RB for barrel and RE for endcaps. }

The DTs are located in the barrel region and are partly integrated into the return yoke.  The pseudorapidity coverage is of $|\eta|<1.2$. They are composed of plane cathodes with anode wires in between the planes. The smallest unit of DTs is the drift cell of dimensions 42$\times$13~mm, in which one 50~$\mathrm{\mu m}$ thick anode wire is located. The drift time of charge carriers can be up to around 400~ns.

The CSCs are located in the endcap areas outside of the return yoke. The CSCs coverage is $0.9<|\eta|<2.4$, which is partly overlapping with the DTs. The CSCs also contain cathodes with anode wires in between, but one cathode of the pair is segmented into strips. The DTs and CSCs provide a good triggering of muons.

To ensure the correct bunch crossing identification~(i.e. from which bunch crossing a given muon originates), the complementary RPCs are present in both barrel and endcap regions. RPCs are composed of parallel plates of anodes and cathodes and readout strips. The RPCs are faster than DTs and CSCs, but provide a worse position resolution. The RPCs trigger is independent of the CSCs and DTs.  

The spatial hit resolution per chamber differs for the three systems, for DTs it is 80-120~$\mathrm{\mu m}$, for CSCs 40-150~$\mathrm{\mu m}$, and for RPCs 0.8-1.2~$\mathrm{cm}$~\cite{Chatrchyan:2013sba}.

In the following the time measurement in the DTs is introduced. The timing can be also measured with the CSCs and the ECAL in a very similar way, but for the purposes of the thesis, only the knowledge of the time measurement in the DTs is needed.


\textbf{Muon timing measurement in the DTs~\label{sec:muonTiming}}

%A muon going through the DTs deposits its energy by ionization of the gas. The created charge carriers drift towards the wires as shown in the blue arrows in Fig.~\ref{fig:figures/dtTiming}~\cite{Traczyk:1365029} and are read at the time $t_{read}$. If the muon is assumed to be produced in-time with the collision~($t_{IP} = 0$) and to travel at the speed of light, then the time ($t_{cell}$) when the muon arrives from the IP to the given drift cell can be calculated. With the knowledge of the drift velocity~$v_{drift}$, and the difference between $t_{read}$ (when the muon charge is read at the wire) and $t_{cell}$ (when the muon arrives to the cell) can be converted into a distance between them. This distance $ v_{drift} (t_{read} - t_{cell})$  is used to compute the hit positions where the muon crossed the cells. If the production time is assumed correctly~(i.e. the muon was created in-time with the collision), the hits are represented by the blue crosses and lie on one straight line. If on the contrary the particle was not produced ``in-time'' with the collision time, then the hits are shifted from the previous positions and are now represented by the red crosses and the line which connects them is no longer straight, but curly. The hit positions in blue crosses are determined by a fitting procedure which minimizes the $\delta t$ offsets. The distance between the reconstructed hit and the hit on the straight line shown as a red segment is converted to the time~$\delta t$, which measures the real arrival time of muon with respect to the expected arrival time, and thus can be used to compute the muon timing.

For each of the DT segment, a local muon timing measurement is performed. A muon going through the DT segment deposits its energy by ionization of the gas. The created charge carriers drift towards the wires as illustrated by the blue arrows in Fig.~\ref{fig:figures/dtTiming}~\cite{Traczyk:1365029} and are read at the time $t_{read}$. The time, $t_{cell}$,  when the muon arrives from the IP to the given drift cell can be calculated under the assumption of the muon production time and that it travels at the speed of light. With the knowledge of the drift velocity~$v_{drift}$, the difference between $t_{read}$ and $t_{cell}$  can be converted into a distance between them. This distance $ v_{drift} (t_{read} - t_{cell})$  is used to compute the hit positions (illustrated by the red crosses), where the muon crossed the cells.  If the production time of muon is correctly assumed, the hits in the red crosses lie around a straight line. On the contrary, if the production time is not correctly assumed,  then the line which connects the red crosses is no longer straight, but curly. To determine the production time, the hit positions in the red crosses are fitted by a three-parameter function,  where the parameters are the position and slope of the line, and the production time $t_{i}$. This fitting procedure minimizes the $\delta t$ distances, i.e. the differences between the hit positions at the red crosses and the positions predicted by the fit function (blue crosses), which depend on the production time $t_{i}$. 
%The determined $\delta t$ distances measure the real arrival time of the muon with respect to the expected arrival time, and thus can be used to compute the muon timing.

% If the production time is assumed correctly~(i.e. the muon was created in-time with the collision), the hits are represented by the blue crosses and lie on one straight line. If on the contrary the particle was not produced ``in-time'' with the collision time, then the hits are shifted from the previous positions and are now represented by the red crosses and the line which connects them is no longer straight, but curly. The hit positions in blue crosses are determined by a fitting procedure which minimizes the $\delta t$ offsets. The distance between the reconstructed hit and the hit on the straight line shown as a red segment is converted to the time~$\delta t$, which measures the real arrival time of muon with respect to the expected arrival time, and thus can be used to compute the muon timing.

    \insertFigure{figures/dtTiming} % Filename = label
                 {0.5}       % Width, in fraction of the whole page width
                 { A schema of a transverse view of few drift cells of the DTs. The wires are shown as black dots, the drift direction as blue arrows, the reconstructed hits as red crosses and the fit function as green arrow. The distance between the reconstructed hits and  the positions predicted by the fit function (blue crosses) is denoted as $\delta t$. The time when the charges were read by a wire is denoted as $t_{read}$~\cite{Traczyk:1365029}.  }

The local timing measurements in segments are combined to produce, among others, the following variables: 

\begin{description}
\item [$\mathbf{time_{IP}^{InOut}}$]
This variable corresponds to the time at which a muon was present at the interaction point, assuming that the muon moves at the speed of light from the IP outside of CMS. It is computed as a weighted average $\bar{t}$ of the measured $t_{i}$ values, where $i$ denotes a single segment measurement. In case of the DTs each weight is equal to $N_{s,i}-2$, with $N_{s,i}$ being the number of hits in the segment of DTs in which the given $t_{i}$ was measured. The formula is then
\eq{timingResol}
{
 \bar{t} = \frac{1}{N} \times \frac{1}{\sum{N_{s,~i} - 2}} \times \sum{ (N_{s, i} -2)  t_{i} },
}
where $N$ is the number of timing measurements.

The error on the time measurement is computed as
\eq{timingResol}
{
 \sigma^{2} = \frac{1}{N-1} \times \frac{1}{\sum{w_{i}}} \times \sum{( t_{i}-\bar{t})^2 w_{i} },
}
where the weight $w_{i}$ is defined as $w_i = 1/\sigma_{i}^2$ with $\sigma_{i}$ being a single timing measurement resolution and $\bar{t}$ is the above defined weighted average of the $t_{i}$ measurements.

\item[$\mathbf{time_{IP}^{OutIn}}$ ]
The $time_{IP}^{OutIn}$ is the muon time at the interaction point assuming that the muon moves from the outside of the CMS detector towards the IP. During the calculation, each $t_{i}$ measurement is increased by twice the time-of-flight~(TOF) of an in-time muon from the IP to the DT segment measuring the $t_{i}$ to take into account that the OutIn muon which was at IP at the same time as the InOut one arrived to the DTs twice TOFs before the InOut muon. Then the computation of timing continues as for the $time_{IP}^{InOut}$.

\item[\textbf{Direction}]
The direction variable provides a simple and robust estimate if the muon traveled from the IP out or in the opposite way. The evaluation takes into account the errors on the $time_{IP}^{OutIn}$ and $time_{IP}^{InOut}$ variables and assumes that the correct time hypothesis has the smallest error.

\item[\textbf{Free} $\mathbf{1/\beta}$]
The free inverse beta (free $1/\beta$) variable is the $c/v$, where $c$ is the speed of light and $v$ the speed of the muon.  It is obtained from the fit of muon time-of-flight measurements. The word ``free'' indicates that neither the production time, the direction nor the velocity is assumed and that all three are free parameters. The muons, originating from collisions reaching the muon chambers, travel from inside towards outside of detector at the speed close to the speed-of-light and therefore their free inverse beta is close to one. The free inverse beta for cosmic muons is around minus one due to the opposite direction.

The timing resolution for DTs is further discussed in Chapter~\ref{ch:simu}.

%The timing resolution for DTs in Run~I was determined to be 7-9~ns~\cite{Traczyk:1365029}, compared to 2.3~ns obtained from simulation. The measured resolution is expected to decrease as the detector synchronization improves.

\end{description}
%-on top of it
 %CMS being synchronized "top-down" for cosmic runs, so that a cosmic muon going vertically down is always in-time (or "at the same time" to be more precise). So basically the DT system is timed for muons going straight down. (just like for collisions it's timed for muons going outwards from IP).In practical terms. The "muons" collection takes as timeAtIpInOut what is more or less the mean of the segment times for a muon. Because it's assuming that the muon is propagating in the same direction that the system is synchronized in. From my observations above it looks like this is the case, the system is synchronized for downward-going cosmics. - not the case in the paper

\subsection{Trigger and data acquisition}

As bunches are colliding every 25~ns, thus with a rate of 40~MHz, fast and reliable triggering system~\cite{Khachatryan:2016bia} is required. The raw data size of one event is approximately 1~MB, therefore if there would not be any dedicated trigger, 40~TB of data per second would have to be stored, what is far beyond the current technical capacities. In CMS there are two levels of triggers which provide physics motivated selection of the interesting events. The first one, called Level-1~(L1), is hardware based and its decision-making is based on information from the muon chambers and the calorimeters. The L1 is capable to take a decision within 3.4~$\mathrm{\mu s}$ and its output rate is up to around 100~kHz. The rest of the event is read upon the decision of the L1 and sent to the second level called High Level Trigger~(HLT). The HLT is a software based trigger providing further selections. At the HLT level, information from all subdetectors is read and therefore the full event can be reconstructed. The output rate of the HLT is around 1~kHz. The time period of uninterrupted data-taking is called a run and ideally there is one run per a LHC fill, where a fill represents the lifetime of a given proton beam in the LHC machine. In the case of  detector technical difficulties the run can be interrupted and a new one started. Once the beams are dumped the run is stopped and a new run of cosmics instead of collision data-taking can start.

%The trigger can be set to select different kind of events. In case of Zero Bias trigger there is no requirement. In the Minimum Bias events, the trigger is firing on any bunch crossing with minimal requirement on the activity in the detector. More dedicated trigge triggerr is for example Single Muon trigger, which requires presence of one muon. 

During collision runs, most of the triggers are dedicated to record events useful for the physics analyses (triggering on events with the presence of e.g. one single muon, two muons, or a large \MET value). Part of the triggers can be used for calibration purposes, such as the Zero Bias and Minimum Bias triggers which fire on any bunch crossing leading to a minimal activity in the detector.

\subsection{Luminosity and pileup}

In particle physics experiments it is very important to have information about an expected event rate during a time period. For this evaluation, the following formula can be used

\eq{nev}
{
 \frac{\mathrm{d}N}{\mathrm{d}t} = \sigma \times \mathcal{L},
}
where $\sigma$ is the cross section of process of interest and $\mathcal{L}$ is the instantaneous luminosity given by

\eq{luminosity}
{
 \mathcal{L} = \frac{N_{b}^2 n_{b} f \gamma}{4 \pi \epsilon_{n} \beta^{*}}F,
}
where the variables in numerator are \textcolor{red}{the number of particles per bunch $N_{b}$ (around $10^{11}$), the $n_{b}$ number of bunches per beam and the bunch crossing frequency $f$ (currently 40~MHz)}. In the denominator, $\epsilon_{n}$ is the normalized transverse beam emittance and $\beta^{*}$ is the beam amplitude function at the IP. The $\beta^{*}$ function  is defined as the distance from the focus point (IP) to the point where the beam is twice as wide as at the focus point and is expressing how much the beam is ``squeezed'' before the collision: lower the $\beta^{*}$ is, more  the beam is squeezed. At the LHC, the  $\epsilon_{n}$ is of the order of 4~mm~$\mathrm{\mu m}$ and $\beta^{*}$ of the order of 0.5~m. Lastly, because of the beam crossing angle, the reduction factor $F$ is introduced. Its value at the LHC is typically around 0.95.

By integration of the instantaneous luminosity over time, the integrated luminosity can be obtained:

\eq{intluminosity}
{
 L = \int{ \mathcal{L} \mathrm{d}t}.
}

The LHC was designed to deliver an instantaneous luminosity of $1 \times 10^{34} \mathrm{cm^{-2}s^{-1}}$.  \textcolor{red}{During Run~2, because of the smooth running and thanks to the large efforts of the LHC group , the LHC instantaneous luminosity was increased}  even beyond the designed luminosity, up to $2.06 \times 10^{34} \mathrm{cm^{-2}s^{-1}}$~\cite{website:CMSlumi}. The integrated luminosity delivered to CMS over years 2010--2017 can be seen in Fig~\ref{fig:figures/cmslumi}~\cite{website:CMSlumi}. A large fraction of integrated luminosity is good to be used in the physics analyses, the rest is being discarded due to a detector problem, for example. \textcolor{red}{For example, in 2016 around 88\% of integrated luminosity was used for physics analyses.} 


    \insertFigure{figures/cmslumi} % Filename = label
                 {0.6}       % Width, in fraction of the whole page width
                 { The delivered luminosity to the CMS detector for years 2010-2017~\cite{website:CMSlumi}. }


High luminosity is essential to study rare processes, but on the other hand it results in effect called pileup~(PU)~\cite{Bayatian:2006nff}. Pileup particles are particles which are not originating from the interaction of interest at a given bunch crossing. The pileup can be divided into two categories, in-time and out-of-time pileup. \textcolor{red}{The in-time pileup is caused by multiple pp interactions in the event, the average pileup for all years of Run~2 is shown in Fig.~\ref{fig:figures/PU}.}  The out-of-time pileup~(OOT PU) originates from particles produced before or after the bunch crossing of interest. The OOT PU is caused for example by slow particles looping in the detector for more bunch crossings or due to the duration of integration of the signal charge by the front-end electronics, resulting in a pulse shape which is typically longer than 25~ns, depending on the subdetector. Because of the wide signal pulse shape, the signal from one particle can be read during more bunch crossings.

    \insertFigure{figures/PU} % Filename = label
                 {0.9}       % Width, in fraction of the whole page width
                 { \textcolor{red}{The average pileup for all years of Run~2~\cite{website:CMSlumi}}. }

\section{Event and object reconstruction at CMS~\label{sec:objects}}

%The events triggered by the HLT are saved in RAW data format which contains the raw information from the detector. The data in the RAW format are then processed in order to reconstruct physics objects. The output of such reconstruction is saved in the RECO format. Most physics analyses do not need all the information present in the RECO files, and thus these files are slimmed to up to a miniAOD~\cite{Petrucciani:2029414} format in order to save space and computing time (in 2017, there is an effort to slim even further the size of the data, going from miniAOD to nanoAOD format). In the miniAOD the event size is reduced by factor of around 60 compared to the RECO event size. 

In this section several physics objects, which are important for the analyses discussed in this thesis, are introduced.


\subsection{The Particle-Flow algorithm}

As it can be seen in Fig.~\ref{fig:figures/CMStransverse}~\cite{Sirunyan:2017ulk} each kind of particle leaves a characteristic signature in the CMS detector. For example, an electron leaves a track in the tracker and then stops in the ECAL where it deposits the rest of its energy. The neutral hadron does not interact in the tracker but can leave energy both in ECAL and  HCAL where it stops.

    \insertFigure{figures/CMStransverse} % Filename = label
                 {0.9}       % Width, in fraction of the whole page width
                 { Transverse view through a sector of the CMS detector. The depositions of different particles in different subdetectors are indicated in the picture~\cite{Sirunyan:2017ulk}. }

The CMS approach to reconstruct an event takes this into account and combines information from all subdetectors at once to reconstruct the objects. The algorithm used for this kind of reconstruction is called the Particle Flow~(PF) algorithm~\cite{Sirunyan:2017ulk}. This algorithm is linking particle deposits in the different subdetectors using specific procedures which depend on the subdetectors and particles. The PF charged hadrons are reconstructed by linking the deposits in an ($\eta,\Phi$) window. In addition to a geometrical matching, the tracks from the tracker are matched with the clusters in calorimeters based on comparing the momentum and energy from tracker and calorimeters. The reconstruction of the PF charged hadrons is also ensuring that there is no deposit in the muon chambers. Such procedure improves both energy and direction determination of the charged hadrons. The PF neutral particles are reconstructed from the clusters in the calorimeters under the photon or neutral hadron hypothesis. The prompt PF electron reconstruction requires both the presence of  ECAL and tracker deposits but the absence of HCAL deposits. The prompt PF muon is reconstructed from a track in the tracker and a track in the muon chambers and its momentum is determined either from the tracker measurement alone or from a combination of the two, depending which option is providing the best momentum measurement.

%linking in (eta, phi) between subdetectors
%The combination of the measurements in the tracker and in the calorimeters provides an improved determination of the energy and di- rection of each charged hadron

\subsection{Leptons}

\subsubsection{Muons}

Muons are traversing the whole CMS detector and therefore their tracks can be reconstructed in both the silicon tracker and the muon chambers. The ``standalone muon'' is a muon track reconstructed from the hits in CSC, DT and RPC, while the ``inner track muon'' is reconstructed from the hits in the silicon strip tracker only. \textcolor{red}{Additionaly, there} are two options how to reconstruct muons using both information from the muon chambers and the tracker. The first one leads to the collection of muons called ``tracker muons''.  The tracker muons are first reconstructed in the tracker and then they are extrapolated to the muon chambers by matching the inner track with hits in the muon chambers. The second approach matches the standalone muon with an inner track based on geometrical criteria. Then the combined track is refitted and the resulting collection is called ``global muons''~\cite{Chatrchyan:2012xi}. 

The PF algorithm uses both global and tracker muons to identify a PF muon. The leptons originating from the hard scattering (prompt muons)  are decay products of e.g. W, Z and H boson and therefore they are not expected not to have any other activity in the proximity. A requirement on muon isolation is added in order to select a muon and reject jets misidentified as muons or muons from decay of heavy flavor quarks. The selected muons are then tested by several quality requirements to balance the efficiency and purity of the muon selection. Based on given criteria, several muon identifications (IDs) and their working points are assessed, e.g. loose, medium, tight. Muons are being reconstructed up to $|\eta|=2.4$ with a reconstruction and identification efficiency larger than 96\%. The muon trigger efficiency is higher than 90\% in  the full $\eta$ range. Using information from both tracker and muon chambers the \pt resolution for muons with 20<\pt<100~GeV is 1.3--2.0\% in the barrel region and better than 6\% in the endcaps. For muons with \pt up to 1~TeV the transverse momentum resolution does not go above 10\%~\cite{Chatrchyan:2012xi}.

\subsubsection{Electrons}

The electrons are reconstructed with the track information from the tracker and the energy deposits in the ECAL~\cite{Khachatryan:2015hwa}. Because of bremsstrahlung, an electron looses in average around 30\% of its energy before reaching the ECAL \textcolor{red}{in $|\eta| \approx 0$}. The energy deposit in the ECAL is reconstructed as a supercluster. \textcolor{red}{A supercluster is a cluster extended in the $\Phi$ direction to take  into account the bremsstrahlung photons.} \textcolor{red}{The electron track in the tracker is not reconstructed by the standard CTF algorithm, but GSF algorithm is used instead to include also bremstrahlung photons~\cite{Adam:2003kg}. The GSF algorithm is starting either from the seed created by a few tracker hits or from the ECAL supercluster and then the track is extrapolated from the seed to the full tracker.} In case of a tracker-based seeding, the next step is to match the ECAL supercluster with the electron track. Similarly as for the muons, an isolation criterion is requested for the prompt electrons as well as quality requirements on the reconstructed electrons are imposed resulting in several electron IDs and categories of these IDs, e.g. loose, medium, tight.

Electrons are reconstructed up to $|\eta|=2.5$,  with an efficiency higher than 88\% in the \pt range from 10~GeV to 100~GeV and $|\eta|<2$. The energy measurement in the ECAL and the momentum measurement in the tracker are used to estimate the momenta of electrons. The resolution on the momentum measurement is evaluated from $Z \rightarrow ee$ decays and its is between 1.7\%-4.5\% for electrons with  \pt~$\approx$~45~GeV~\cite{Khachatryan:2015hwa}.



\subsubsection{Taus}

In around 2/3 of the cases the tau leptons decay hadronically to a mixture of charged and neutral hadrons and tau neutrino. The decay is very fast and thus it is difficult to reconstruct the secondary vertex. The algorithm which is used to identify the hadronically decaying tau is called Hadron-Plus-Strips~(HPS)~\cite{CMS:2016gvn}. The probability to misidentify a jet, an electron or a muon as an hadronic tau  depends on the objects identification requirement and was measured in data to be around 0.01\%-4\%, 0.1\%-3\% or 0.03\%-0.3\%, respectively. Large differences were found in misidentification rate between data and simulation, leading to data to simulation ratio up to 1.66 in the case of an electron, 1.86 in the case of a muon and between 0.8 and 1.2 in the case of a jet. The hadronic tau identification efficiency is of around 50-60\% and is similar for data and simulation~\cite{Khachatryan:2015dfa}. The probability to misidentify a jet, an electron or a muon as an hadronic tau  depends on the objects identification requirement and was measured in data to be around 0.01\%-4\%, 0.1\%-3\% or 0.03\%-0.3\%, respectively. Large differences were found in misidentification rate between data and simulation, leading to data to simulation ratio up to 1.66 in the case of an electron, 1.86 in the case of a muon and between 0.8 and 1.2 in the case of a jet. The hadronic tau identification efficiency is of around 50-60\% and is similar for data and simulation~\cite{Khachatryan:2015dfa}.

%This algorithm searches for the neutral pions present in the majority of hadronic tau decays. The neutral pion, originating from the tau, decays to a photon pair, the photons later converting to an electron/positron pair. These electrons/positrons bend in the magnetic field and thus broaden the energy deposits in the ECAL in the azimuthal direction beyond the size of the reconstructed hadronic tau jet. To take this effect into account, the electromagnetic particles  are reconstructed in a fixed size $\Delta \eta \times \Delta \Phi$ window called ``strip''. 
%The strip is first associated with the most energetic electron or photon within the PF jet. Then the algorithm looks within the given window whether another electromagnetic particle is present close to the selected one. If present, this particle is added to the strip. The algorithm proceeds up to the point where no other electromagnetic particle is present in the $\Delta \eta \times \Delta \Phi$ strip. Then the most energetic electromagnetic particle not belonging to any strip is associated to a new strip and the algorithm proceeds as before. The final algorithm searches for the hadronic taus in topologies with a single hadron, one hadron and one strip, one hadron and two strips, and three hadrons. 


%The tau identification efficiency is measured in perspective of deriving data to simaltion scale factors. These factors vary from 0.83 to 0.96, depending on the tau identification technique.


\subsection{Photons}

Photons do not leave tracks in the tracker and thus their energy is obtained only from ECAL measurements. The prompt photon identification is based on two categories of observables, its shower shape and its isolation from the remaining activity in the ECAL. Again, there are several photon identifications (IDs), for each of them three working points are defined: loose, medium and tight. Due to the high material budget before the ECAL, the photon can convert to the electron-positron pair before reaching the ECAL. The achieved resolution in the barrel region  on both the unconverted and converted photon energies varies between 1\% and 2.5\% for photons with an energy of tens of GeV. In the endcaps the photon energy resolution for unconverted and converted photons is of 2.5\%-4\%~\cite{CMS:EGM-14-001}.

\subsection{Jets}

The production of quarks and gluons is followed by radiations and hadronization, this results in a large activity in a narrow cone. In order to reconstruct these particles the $\mathrm{anti-}k_{T}$~(ak) clustering algorithm~\cite{Cacciari:2008gp, Cacciari:2011ma} is used. Within this algorithm the distance between objects is defined as

\eq{antikt}
{   
    d_{ij} = \mathrm{min}\left({p_{T}}^{-2}(i), {p_{T}}^{-2}(j)\right) \frac{(\eta_{i} -\eta_{j})^2+ (\Phi_{i} -\Phi_{j})^2}{R^2} =  \mathrm{min}({p_{T}}^{-2}(i), {p_{T}}^{-2}(j)) \frac{\Delta R_{ij}^{2}}{R^2},
}
where $p_{T}(i)$ is the transverse momentum, $\eta_{i}$  the pseudorapidity and $\Phi_{i}$ the azimuthal angle of the object $i$. To reconstruct PF jets, the algorithm runs over PF reconstructed candidates such as electrons, muons, photons, charged and neutral hadrons. The parameter $R$ is a jet distance parameter. In the standard jet reconstruction, R=0.4  in Run 2 while it was chosen to 0.5 in Run 1, this decrease is due to the change of the energy and pileup between these two Runs. In the case of boosted objects decaying to partons, two or more jets originating from the boosted parton can be merged. These topologies can be reconstructed as so called ``fat jets'', and for purpose of their reconstruction, the parameter $R$ is increased to 0.8 or 1.0. The $\mathrm{anti-}k_{T}$ algorithm, by definition, tends to cluster first the high \pt objects with the shortest distance between each other and continues with objects further apart. After all high \pt particles are clustered, the clustering algorithm adds all low \pt particles in the cone specified by the parameter $R$. The product of the clustering is a jet. The charged component of the jet can be reconstructed only up to $|\eta|=2.4$ due to the tracker coverage, while the neutral component extends up to  $|\eta|=5$.

The measured jet energy is in general not equal to the energy of parton responsible for the jet, due to several inefficiencies and biases in the energy measurement. Therefore the jet energy must be calibrated and rescaled by the correction factor in order to have a correct jet energy scale. The jet energy corrections are obtained from simulations. An additional jet energy scale correction is derived from measured dijet, photon+jet, Z+jet, and multijet events to take into account differences between data and simulation~\cite{Khachatryan:2016kdb}. The typical PF jet energy resolution is around 15\% for 10~GeV jets, 8\% for 100~GeV jets, and 4\% for 1~TeV jets. %from page det 

\subsection{b-jets}

In order to determine from which quark the jet is originating, flavor tagging techniques were developed. The target of the heavy flavor tagging techniques is to identify jets originating from a b quark~(b-jets) or a c quark~(c-jets). In the following, only b-jets are discussed. The b-quarks are forming B-mesons, which decay within about 1.5 ns creating a secondary vertex  displaced by few mm up to cm from the primary vertex. The information on a displaced secondary vertex or displaced tracks in the jet, information about tracks originating from the secondary vertex and optionally information on soft leptons within the jet are used by b-tagging algorithms to tag jets formed from the b-quarks~\cite{Sirunyan:2017ezt}. Due to the tracker geometry, b-jets can be reconstructed only up to $|\eta|=2.4$.

There are several algorithms, whose purpose is to tag a b-jet. The first one is the Combined Secondary Vertex~(CSVv2) algorithm, which combines information about displaced tracks with information on the secondary vertex. The DeepCSV algorithm improves the performance with respect to the CSVv2 algorithm by using a deep neural network. The Combined Multivariate Analysis~(cMVAv2) technique takes into account a fact, that B-hadrons can decay leptonically and thus soft electrons or muons can be present in the b-jet. In this algorithm, the information about soft leptons is used in combination with other taggers. The efficiency to tag a b-jet versus the probability to misidentify a c or light flavor jet as a b-jet for different taggers is shown in Fig.~\ref{fig:figures/btag}~\cite{Sirunyan:2017ezt}, as estimated from simulation. For each b-tagging algorithm, loose, medium and tight working points are defined. These working points are defined by requiring a threshold on the misidentification probability of around 10\% for loose, 1\% for medium and 0.1\% for tight working points. As for many other objects, the scale factors are then derived to correct for different performances in data and simulation.


    \insertFigure{figures/btag} % Filename = label
                 {0.7}       % Width, in fraction of the whole page width
                 { The probability to misidentify a c or light flavor jet as a b-jet versus the efficiency to identify a b-jet for different b-tagging algorithms. These curves were evaluated from simulated $t\bar{t}$+jets events, using jets with \pt > 20 GeV~\cite{Sirunyan:2017ezt}. }

%The performance of b-jet taggers is different in data and event simulations therefore a multiplicative data-to-simulation factor must be used on top of the simulation in order to compensate for the differences.

\subsection{Missing transverse energy~\label{sec:MET}}


If the momenta of all particles could be measured, the sum of all momenta in the plane transverse to the beam would be zero due to the momentum conservation law. But as neutrinos escape the detector undetected, an imbalance of momentum in this plane could be observed. 

The Missing Transverse Momentum, for simplicity referred to as ``Missing Transverse Energy''~($E_{T}^{miss}$) is the magnitude of the negative vectorial sum of the transverse momenta of all PF particles~\cite{CMS:2016ljj} and is computed as

\eq{mtm}
{
E_{T}^{miss} = \abs{-\sum_{i} \vec{p}_{T_{i}}},
}
where $\vec{p}_{T_{i}}$ is the momentum of $i$-th PF particle. Because of energy thresholds in the calorimeters, inefficiencies in the tracker or non-linearity of the calorimeters' response for hadrons, the \MET measurement can be biased and thus an energy correction factor must be used. This factor accounts for effects influencing the \MET and is applied on the transverse momenta of the jets. The \MET is then recomputed with the new transverse momenta of jets. The uncertainty on \MET is evaluated by varying the $p_{T}$ of each kind of object within its resolution. The  \MET  distributions for  $Z \rightarrow ee$ and $Z \rightarrow \mu \mu$ events are shown in Fig.~\ref{fig:figures/met}~\cite{CMS:2016ljj}. These plots show a good agreement between data and simulation. The $Z \rightarrow ee$ and $Z \rightarrow \mu \mu$ events have no genuine source of the \MET , no neutrino in the final states. Therefore the \MET is expected to be zero, but due to the \MET resolution, non-zero values are observed.  


    \insertFigure{figures/met} % Filename = label
                 {0.9}       % Width, in fraction of the whole page width
                 { \MET distributions for $Z \rightarrow \mu \mu$~(left) and $Z \rightarrow ee$~(right) events with the data to simulation ratio in the bottom canvas. There is also a contribution from two other groups of processes decaying to the dimuon or dielectron final states. The Top contribution originates from $t\bar{t}$ and single top processes, in which the W-bosons decay leptonically to a charged lepton and a neutrino and therefore these events have a genuine source of \MET. The EWK group of processes consists of diboson, $Z\gamma$ and $W\gamma$ production processes, which are also partly present in the \MET tail due to leptonically decaying W-bosons in some of them~\cite{CMS:2016ljj}. }

The \MET variable plays a crucial role in searches for physics beyond the Standard Model, as many theories predict stable weekly interacting particles which would enhance the \MET.



